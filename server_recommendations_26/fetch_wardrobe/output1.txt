Analyzing image: D:\Dinesh\Tech\GitHub\virtual-assistant\images\resized_image\women\F 1.jpg
{'modelVersion': '2023-10-01', 'captionResult': {'text': 'a woman in a black dress and tan trench coat', 'confidence': 0.7984259128570557}, 'denseCaptionsResult': {'values': [{'text': 'a woman in a black dress and tan trench coat', 'confidence': 0.7984259128570557, 'boundingBox': {'x': 0, 'y': 0, 'w': 400, 'h': 800}}, {'text': 'a woman wearing a black dress and a trench coat', 'confidence': 0.7748208045959473, 'boundingBox': {'x': 107, 'y': 21, 'w': 182, 'h': 756}}, {'text': 'a close up of a black object', 'confidence': 0.6621670126914978, 'boundingBox': {'x': 236, 'y': 432, 'w': 59, 'h': 192}}, {'text': 'a woman with long hair', 'confidence': 0.7169262170791626, 'boundingBox': {'x': 156, 'y': 33, 'w': 120, 'h': 158}}]}, 'metadata': {'width': 400, 'height': 800}, 'tagsResult': {'values': [{'name': 'clothing', 'confidence': 0.9987072944641113}, {'name': 'fashion', 'confidence': 0.9867891073226929}, {'name': 'person', 'confidence': 0.976088285446167}, {'name': 'fashion design', 'confidence': 0.9718385934829712}, {'name': 'fashion model', 'confidence': 0.9636294841766357}, {'name': 'footwear', 'confidence': 0.9250125885009766}, {'name': 'fashion show', 'confidence': 0.9154960513114929}, {'name': 'coat', 'confidence': 0.9043012857437134}, {'name': 'outerwear', 'confidence': 0.8962482213973999}, {'name': 'high heels', 'confidence': 0.8928102850914001}, {'name': 'overcoat', 'confidence': 0.8869194388389587}, {'name': 'trench coat', 'confidence': 0.8789054155349731}, {'name': 'shoulder', 'confidence': 0.8684109449386597}, {'name': 'street fashion', 'confidence': 0.858099102973938}, {'name': 'duster', 'confidence': 0.8536352515220642}, {'name': 'casual dress', 'confidence': 0.8510898351669312}, {'name': 'fashion accessory', 'confidence': 0.8424944877624512}, {'name': 'indoor', 'confidence': 0.7973933219909668}, {'name': 'woman', 'confidence': 0.7413569688796997}, {'name': 'fabric', 'confidence': 0.6033467650413513}]}, 'objectsResult': {'values': []}, 'readResult': {'blocks': []}, 'peopleResult': {'values': [{'boundingBox': {'x': 115, 'y': 35, 'w': 179, 'h': 758}, 'confidence': 0.8619827628135681}, {'boundingBox': {'x': 42, 'y': 209, 'w': 39, 'h': 79}, 'confidence': 0.12631462514400482}, {'boundingBox': {'x': 121, 'y': 300, 'w': 153, 'h': 202}, 'confidence': 0.0020625386387109756}, {'boundingBox': {'x': 36, 'y': 207, 'w': 52, 'h': 198}, 'confidence': 0.0018035309622064233}, {'boundingBox': {'x': 329, 'y': 255, 'w': 43, 'h': 123}, 'confidence': 0.001364989671856165}]}}
Caption: a woman in a black dress and tan trench coat (Confidence: 0.7984259128570557)
Tags:
- clothing (Confidence: 0.9987072944641113)
- fashion (Confidence: 0.9867891073226929)
- person (Confidence: 0.976088285446167)
- fashion design (Confidence: 0.9718385934829712)
- fashion model (Confidence: 0.9636294841766357)
- footwear (Confidence: 0.9250125885009766)
- fashion show (Confidence: 0.9154960513114929)
- coat (Confidence: 0.9043012857437134)
- outerwear (Confidence: 0.8962482213973999)
- high heels (Confidence: 0.8928102850914001)
- overcoat (Confidence: 0.8869194388389587)
- trench coat (Confidence: 0.8789054155349731)
- shoulder (Confidence: 0.8684109449386597)
- street fashion (Confidence: 0.858099102973938)
- duster (Confidence: 0.8536352515220642)
- casual dress (Confidence: 0.8510898351669312)
- fashion accessory (Confidence: 0.8424944877624512)
- indoor (Confidence: 0.7973933219909668)
- woman (Confidence: 0.7413569688796997)
- fabric (Confidence: 0.6033467650413513)
Dense Captions:
- a woman in a black dress and tan trench coat (Confidence: 0.7984259128570557)
- a woman wearing a black dress and a trench coat (Confidence: 0.7748208045959473)
- a close up of a black object (Confidence: 0.6621670126914978)
- a woman with long hair (Confidence: 0.7169262170791626)
Analyzing image: D:\Dinesh\Tech\GitHub\virtual-assistant\images\resized_image\women\F 10.jpg
{'modelVersion': '2023-10-01', 'captionResult': {'text': 'a woman in a pink suit', 'confidence': 0.851831316947937}, 'denseCaptionsResult': {'values': [{'text': 'a woman in a pink suit', 'confidence': 0.8514387011528015, 'boundingBox': {'x': 0, 'y': 0, 'w': 400, 'h': 800}}, {'text': 'a woman in a pink suit', 'confidence': 0.814492404460907, 'boundingBox': {'x': 122, 'y': 164, 'w': 151, 'h': 519}}, {'text': 'a woman wearing a pink skirt', 'confidence': 0.7633144855499268, 'boundingBox': {'x': 131, 'y': 374, 'w': 123, 'h': 256}}, {'text': 'a woman in a pink jacket', 'confidence': 0.7713363766670227, 'boundingBox': {'x': 124, 'y': 161, 'w': 113, 'h': 199}}, {'text': 'a woman in a pink suit', 'confidence': 0.8407079577445984, 'boundingBox': {'x': 17, 'y': 110, 'w': 337, 'h': 621}}, {'text': 'a woman wearing a pink suit', 'confidence': 0.8273497819900513, 'boundingBox': {'x': 115, 'y': 256, 'w': 154, 'h': 211}}]}, 'metadata': {'width': 400, 'height': 800}, 'tagsResult': {'values': [{'name': 'clothing', 'confidence': 0.9921492338180542}, {'name': 'person', 'confidence': 0.9780027866363525}, {'name': 'human face', 'confidence': 0.9359349608421326}, {'name': 'fashion', 'confidence': 0.9355292320251465}, {'name': 'fashion design', 'confidence': 0.9149783849716187}, {'name': 'day dress', 'confidence': 0.8970587849617004}, {'name': 'shoulder', 'confidence': 0.88905268907547}, {'name': 'fashion model', 'confidence': 0.8766179084777832}, {'name': 'waist', 'confidence': 0.8752461075782776}, {'name': 'casual dress', 'confidence': 0.8431316614151001}, {'name': 'woman', 'confidence': 0.7116224765777588}, {'name': 'dress', 'confidence': 0.6140433549880981}]}, 'objectsResult': {'values': [{'boundingBox': {'x': 120, 'y': 165, 'w': 151, 'h': 488}, 'tags': [{'name': 'person', 'confidence': 0.814}]}]}, 'readResult': {'blocks': []}, 'peopleResult': {'values': [{'boundingBox': {'x': 116, 'y': 164, 'w': 160, 'h': 522}, 'confidence': 0.9341841340065002}]}}
Caption: a woman in a pink suit (Confidence: 0.851831316947937)
Tags:
- clothing (Confidence: 0.9921492338180542)
- person (Confidence: 0.9780027866363525)
- human face (Confidence: 0.9359349608421326)
- fashion (Confidence: 0.9355292320251465)
- fashion design (Confidence: 0.9149783849716187)
- day dress (Confidence: 0.8970587849617004)
- shoulder (Confidence: 0.88905268907547)
- fashion model (Confidence: 0.8766179084777832)
- waist (Confidence: 0.8752461075782776)
- casual dress (Confidence: 0.8431316614151001)
- woman (Confidence: 0.7116224765777588)
- dress (Confidence: 0.6140433549880981)
Dense Captions:
- a woman in a pink suit (Confidence: 0.8514387011528015)
- a woman in a pink suit (Confidence: 0.814492404460907)
- a woman wearing a pink skirt (Confidence: 0.7633144855499268)
- a woman in a pink jacket (Confidence: 0.7713363766670227)
- a woman in a pink suit (Confidence: 0.8407079577445984)
- a woman wearing a pink suit (Confidence: 0.8273497819900513)
Analyzing image: D:\Dinesh\Tech\GitHub\virtual-assistant\images\resized_image\women\F 11.jpg
{'modelVersion': '2023-10-01', 'captionResult': {'text': 'a woman wearing a white shirt and black skirt', 'confidence': 0.7984779477119446}, 'denseCaptionsResult': {'values': [{'text': 'a woman wearing a white shirt and black skirt', 'confidence': 0.7984779477119446, 'boundingBox': {'x': 0, 'y': 0, 'w': 400, 'h': 800}}, {'text': 'a close up of a bag', 'confidence': 0.7624508142471313, 'boundingBox': {'x': 113, 'y': 482, 'w': 82, 'h': 197}}, {'text': 'a woman wearing a black skirt', 'confidence': 0.7739684581756592, 'boundingBox': {'x': 134, 'y': 45, 'w': 169, 'h': 740}}, {'text': "a close-up of a person's foot", 'confidence': 0.8522458076477051, 'boundingBox': {'x': 271, 'y': 143, 'w': 120, 'h': 329}}, {'text': 'a woman wearing a black skirt', 'confidence': 0.7670865654945374, 'boundingBox': {'x': 161, 'y': 323, 'w': 118, 'h': 286}}, {'text': 'a woman with long brown hair', 'confidence': 0.7718188762664795, 'boundingBox': {'x': 165, 'y': 47, 'w': 113, 'h': 171}}]}, 'metadata': {'width': 400, 'height': 800}, 'tagsResult': {'values': [{'name': 'person', 'confidence': 0.9853836297988892}, {'name': 'fashion accessory', 'confidence': 0.9772806167602539}, {'name': 'clothing', 'confidence': 0.9772164821624756}, {'name': 'fashion', 'confidence': 0.9725580215454102}, {'name': 'handbag', 'confidence': 0.9716434478759766}, {'name': 'waist', 'confidence': 0.9615475535392761}, {'name': 'shoulder', 'confidence': 0.9510176181793213}, {'name': 'fashion design', 'confidence': 0.9458508491516113}, {'name': 'high heels', 'confidence': 0.9356070160865784}, {'name': 'skirt', 'confidence': 0.9331506490707397}, {'name': 'fashion model', 'confidence': 0.9280413389205933}, {'name': 'casual dress', 'confidence': 0.9267762303352356}, {'name': 'street fashion', 'confidence': 0.9233736991882324}, {'name': 'miniskirt', 'confidence': 0.9045434594154358}, {'name': 'day dress', 'confidence': 0.9040029048919678}, {'name': 'blouse', 'confidence': 0.8949810862541199}, {'name': 'luggage and bags', 'confidence': 0.8758443593978882}, {'name': 'pocket', 'confidence': 0.8714227676391602}, {'name': 'sandal', 'confidence': 0.8662333488464355}, {'name': 'cocktail dress', 'confidence': 0.8597584962844849}, {'name': 'woman', 'confidence': 0.8515580892562866}, {'name': 'pattern (fashion design)', 'confidence': 0.8475919365882874}, {'name': 'sleeve', 'confidence': 0.843571126461029}, {'name': 'standing', 'confidence': 0.8412718772888184}, {'name': 'outdoor', 'confidence': 0.6565588116645813}]}, 'objectsResult': {'values': [{'boundingBox': {'x': 115, 'y': 462, 'w': 90, 'h': 223}, 'tags': [{'name': 'handbag', 'confidence': 0.649}]}, {'boundingBox': {'x': 139, 'y': 74, 'w': 173, 'h': 478}, 'tags': [{'name': 'person', 'confidence': 0.628}]}]}, 'readResult': {'blocks': []}, 'peopleResult': {'values': [{'boundingBox': {'x': 142, 'y': 52, 'w': 170, 'h': 747}, 'confidence': 0.9214467406272888}, {'boundingBox': {'x': 151, 'y': 330, 'w': 156, 'h': 211}, 'confidence': 0.001870850333943963}]}}
Caption: a woman wearing a white shirt and black skirt (Confidence: 0.7984779477119446)
Tags:
- person (Confidence: 0.9853836297988892)
- fashion accessory (Confidence: 0.9772806167602539)
- clothing (Confidence: 0.9772164821624756)
- fashion (Confidence: 0.9725580215454102)
- handbag (Confidence: 0.9716434478759766)
- waist (Confidence: 0.9615475535392761)
- shoulder (Confidence: 0.9510176181793213)
- fashion design (Confidence: 0.9458508491516113)
- high heels (Confidence: 0.9356070160865784)
- skirt (Confidence: 0.9331506490707397)
- fashion model (Confidence: 0.9280413389205933)
- casual dress (Confidence: 0.9267762303352356)
- street fashion (Confidence: 0.9233736991882324)
- miniskirt (Confidence: 0.9045434594154358)
- day dress (Confidence: 0.9040029048919678)
- blouse (Confidence: 0.8949810862541199)
- luggage and bags (Confidence: 0.8758443593978882)
- pocket (Confidence: 0.8714227676391602)
- sandal (Confidence: 0.8662333488464355)
- cocktail dress (Confidence: 0.8597584962844849)
- woman (Confidence: 0.8515580892562866)
- pattern (fashion design) (Confidence: 0.8475919365882874)
- sleeve (Confidence: 0.843571126461029)
- standing (Confidence: 0.8412718772888184)
- outdoor (Confidence: 0.6565588116645813)
Dense Captions:
- a woman wearing a white shirt and black skirt (Confidence: 0.7984779477119446)
- a close up of a bag (Confidence: 0.7624508142471313)
- a woman wearing a black skirt (Confidence: 0.7739684581756592)
- a close-up of a person's foot (Confidence: 0.8522458076477051)
- a woman wearing a black skirt (Confidence: 0.7670865654945374)
- a woman with long brown hair (Confidence: 0.7718188762664795)
Analyzing image: D:\Dinesh\Tech\GitHub\virtual-assistant\images\resized_image\women\F 2.jpg
{'modelVersion': '2023-10-01', 'captionResult': {'text': 'a woman in a suit and skirt', 'confidence': 0.7338113784790039}, 'denseCaptionsResult': {'values': [{'text': 'a woman in a suit and skirt', 'confidence': 0.7338471412658691, 'boundingBox': {'x': 0, 'y': 0, 'w': 400, 'h': 800}}, {'text': 'a woman wearing a black dress and tan jacket', 'confidence': 0.7346651554107666, 'boundingBox': {'x': 99, 'y': 6, 'w': 183, 'h': 780}}, {'text': 'a blurry picture of a plant', 'confidence': 0.7630556225776672, 'boundingBox': {'x': 0, 'y': 235, 'w': 61, 'h': 319}}, {'text': 'a blurry picture of a tree', 'confidence': 0.7631300091743469, 'boundingBox': {'x': 337, 'y': 308, 'w': 59, 'h': 149}}, {'text': 'a woman with blonde hair', 'confidence': 0.7819589376449585, 'boundingBox': {'x': 142, 'y': 9, 'w': 113, 'h': 149}}]}, 'metadata': {'width': 400, 'height': 800}, 'tagsResult': {'values': [{'name': 'clothing', 'confidence': 0.9978297352790833}, {'name': 'person', 'confidence': 0.9925375580787659}, {'name': 'fashion', 'confidence': 0.9771836400032043}, {'name': 'fashion design', 'confidence': 0.9608058929443359}, {'name': 'collar', 'confidence': 0.9422716498374939}, {'name': 'outerwear', 'confidence': 0.9400631785392761}, {'name': 'shoulder', 'confidence': 0.9391581416130066}, {'name': 'fashion model', 'confidence': 0.9285507202148438}, {'name': 'waist', 'confidence': 0.9276937246322632}, {'name': 'blazer', 'confidence': 0.9248325228691101}, {'name': 'coat', 'confidence': 0.9245637655258179}, {'name': 'high heels', 'confidence': 0.9001359939575195}, {'name': 'footwear', 'confidence': 0.8974721431732178}, {'name': 'casual dress', 'confidence': 0.8898029923439026}, {'name': 'sleeve', 'confidence': 0.8862099647521973}, {'name': 'day dress', 'confidence': 0.8820467591285706}, {'name': 'pocket', 'confidence': 0.8780580759048462}, {'name': 'indoor', 'confidence': 0.8713602423667908}, {'name': 'handbag', 'confidence': 0.8676807284355164}, {'name': 'trench coat', 'confidence': 0.8560391664505005}, {'name': 'fashion accessory', 'confidence': 0.852587103843689}, {'name': 'blouse', 'confidence': 0.8464829921722412}, {'name': 'skirt', 'confidence': 0.8448488712310791}, {'name': 'top', 'confidence': 0.8443198204040527}, {'name': 'cocktail dress', 'confidence': 0.8423999547958374}, {'name': 'woman', 'confidence': 0.7987270355224609}, {'name': 'wall', 'confidence': 0.7475354671478271}, {'name': 'floor', 'confidence': 0.7182116508483887}, {'name': 'wearing', 'confidence': 0.6923815608024597}, {'name': 'standing', 'confidence': 0.6578595042228699}, {'name': 'ground', 'confidence': 0.5571207404136658}]}, 'objectsResult': {'values': []}, 'readResult': {'blocks': []}, 'peopleResult': {'values': [{'boundingBox': {'x': 104, 'y': 6, 'w': 186, 'h': 793}, 'confidence': 0.931286096572876}, {'boundingBox': {'x': 112, 'y': 301, 'w': 164, 'h': 195}, 'confidence': 0.001621755538508296}]}}
Caption: a woman in a suit and skirt (Confidence: 0.7338113784790039)
Tags:
- clothing (Confidence: 0.9978297352790833)
- person (Confidence: 0.9925375580787659)
- fashion (Confidence: 0.9771836400032043)
- fashion design (Confidence: 0.9608058929443359)
- collar (Confidence: 0.9422716498374939)
- outerwear (Confidence: 0.9400631785392761)
- shoulder (Confidence: 0.9391581416130066)
- fashion model (Confidence: 0.9285507202148438)
- waist (Confidence: 0.9276937246322632)
- blazer (Confidence: 0.9248325228691101)
- coat (Confidence: 0.9245637655258179)
- high heels (Confidence: 0.9001359939575195)
- footwear (Confidence: 0.8974721431732178)
- casual dress (Confidence: 0.8898029923439026)
- sleeve (Confidence: 0.8862099647521973)
- day dress (Confidence: 0.8820467591285706)
- pocket (Confidence: 0.8780580759048462)
- indoor (Confidence: 0.8713602423667908)
- handbag (Confidence: 0.8676807284355164)
- trench coat (Confidence: 0.8560391664505005)
- fashion accessory (Confidence: 0.852587103843689)
- blouse (Confidence: 0.8464829921722412)
- skirt (Confidence: 0.8448488712310791)
- top (Confidence: 0.8443198204040527)
- cocktail dress (Confidence: 0.8423999547958374)
- woman (Confidence: 0.7987270355224609)
- wall (Confidence: 0.7475354671478271)
- floor (Confidence: 0.7182116508483887)
- wearing (Confidence: 0.6923815608024597)
- standing (Confidence: 0.6578595042228699)
- ground (Confidence: 0.5571207404136658)
Dense Captions:
- a woman in a suit and skirt (Confidence: 0.7338471412658691)
- a woman wearing a black dress and tan jacket (Confidence: 0.7346651554107666)
- a blurry picture of a plant (Confidence: 0.7630556225776672)
- a blurry picture of a tree (Confidence: 0.7631300091743469)
- a woman with blonde hair (Confidence: 0.7819589376449585)
Analyzing image: D:\Dinesh\Tech\GitHub\virtual-assistant\images\resized_image\women\F 3.jpg
{'modelVersion': '2023-10-01', 'captionResult': {'text': 'a woman in a suit and skirt', 'confidence': 0.708289384841919}, 'denseCaptionsResult': {'values': [{'text': 'a woman in a suit and skirt', 'confidence': 0.708289384841919, 'boundingBox': {'x': 0, 'y': 0, 'w': 400, 'h': 800}}, {'text': 'a woman wearing a skirt and a vest', 'confidence': 0.7180163264274597, 'boundingBox': {'x': 142, 'y': 99, 'w': 120, 'h': 606}}, {'text': 'a woman with long hair', 'confidence': 0.7175929546356201, 'boundingBox': {'x': 144, 'y': 84, 'w': 85, 'h': 172}}]}, 'metadata': {'width': 400, 'height': 800}, 'tagsResult': {'values': [{'name': 'clothing', 'confidence': 0.9957177639007568}, {'name': 'person', 'confidence': 0.9800673127174377}, {'name': 'fashion', 'confidence': 0.9492290616035461}, {'name': 'fashion design', 'confidence': 0.9434827566146851}, {'name': 'coat', 'confidence': 0.9353421330451965}, {'name': 'blazer', 'confidence': 0.9100309610366821}, {'name': 'fashion model', 'confidence': 0.9095709323883057}, {'name': 'outerwear', 'confidence': 0.8849916458129883}, {'name': 'collar', 'confidence': 0.8771324157714844}, {'name': 'day dress', 'confidence': 0.871573805809021}, {'name': 'casual dress', 'confidence': 0.8686463832855225}, {'name': 'dress', 'confidence': 0.8683798313140869}, {'name': 'pattern (fashion design)', 'confidence': 0.865405797958374}, {'name': 'button', 'confidence': 0.8533780574798584}, {'name': 'woman', 'confidence': 0.6967390179634094}, {'name': 'standing', 'confidence': 0.6546507477760315}]}, 'objectsResult': {'values': [{'boundingBox': {'x': 156, 'y': 358, 'w': 95, 'h': 161}, 'tags': [{'name': 'Miniskirt', 'confidence': 0.505}]}, {'boundingBox': {'x': 137, 'y': 96, 'w': 135, 'h': 448}, 'tags': [{'name': 'person', 'confidence': 0.569}]}]}, 'readResult': {'blocks': []}, 'peopleResult': {'values': [{'boundingBox': {'x': 139, 'y': 86, 'w': 130, 'h': 633}, 'confidence': 0.9284332394599915}]}}
Caption: a woman in a suit and skirt (Confidence: 0.708289384841919)
Tags:
- clothing (Confidence: 0.9957177639007568)
- person (Confidence: 0.9800673127174377)
- fashion (Confidence: 0.9492290616035461)
- fashion design (Confidence: 0.9434827566146851)
- coat (Confidence: 0.9353421330451965)
- blazer (Confidence: 0.9100309610366821)
- fashion model (Confidence: 0.9095709323883057)
- outerwear (Confidence: 0.8849916458129883)
- collar (Confidence: 0.8771324157714844)
- day dress (Confidence: 0.871573805809021)
- casual dress (Confidence: 0.8686463832855225)
- dress (Confidence: 0.8683798313140869)
- pattern (fashion design) (Confidence: 0.865405797958374)
- button (Confidence: 0.8533780574798584)
- woman (Confidence: 0.6967390179634094)
- standing (Confidence: 0.6546507477760315)
Dense Captions:
- a woman in a suit and skirt (Confidence: 0.708289384841919)
- a woman wearing a skirt and a vest (Confidence: 0.7180163264274597)
- a woman with long hair (Confidence: 0.7175929546356201)
Analyzing image: D:\Dinesh\Tech\GitHub\virtual-assistant\images\resized_image\women\F 4.jpg
{'modelVersion': '2023-10-01', 'captionResult': {'text': 'a woman in a skirt and blouse', 'confidence': 0.7034857869148254}, 'denseCaptionsResult': {'values': [{'text': 'a woman in a skirt and blouse', 'confidence': 0.7034857869148254, 'boundingBox': {'x': 0, 'y': 0, 'w': 400, 'h': 800}}, {'text': 'a woman wearing a black skirt', 'confidence': 0.8199406266212463, 'boundingBox': {'x': 105, 'y': 68, 'w': 187, 'h': 719}}, {'text': "a close up of a woman's skirt", 'confidence': 0.8041300773620605, 'boundingBox': {'x': 132, 'y': 337, 'w': 132, 'h': 304}}, {'text': 'a woman smiling with her hair blowing in the wind', 'confidence': 0.772121012210846, 'boundingBox': {'x': 111, 'y': 66, 'w': 140, 'h': 139}}]}, 'metadata': {'width': 400, 'height': 800}, 'tagsResult': {'values': [{'name': 'clothing', 'confidence': 0.9936479330062866}, {'name': 'person', 'confidence': 0.9903221130371094}, {'name': 'fashion', 'confidence': 0.9715772271156311}, {'name': 'waist', 'confidence': 0.9683555364608765}, {'name': 'shoulder', 'confidence': 0.9670990705490112}, {'name': 'street fashion', 'confidence': 0.9651206731796265}, {'name': 'fashion model', 'confidence': 0.9378894567489624}, {'name': 'casual dress', 'confidence': 0.9372140169143677}, {'name': 'outdoor', 'confidence': 0.9252172708511353}, {'name': 'lady', 'confidence': 0.9249401092529297}, {'name': 'high heels', 'confidence': 0.9158104658126831}, {'name': 'fashion design', 'confidence': 0.9150017499923706}, {'name': 'blouse', 'confidence': 0.9002287983894348}, {'name': 'building', 'confidence': 0.898080587387085}, {'name': 'female person', 'confidence': 0.8961195945739746}, {'name': 'woman', 'confidence': 0.895744800567627}, {'name': 'fashion accessory', 'confidence': 0.885344922542572}, {'name': 'skirt', 'confidence': 0.8756769299507141}, {'name': 'day dress', 'confidence': 0.8627912998199463}, {'name': 'sleeve', 'confidence': 0.8556791543960571}, {'name': 'photo shoot', 'confidence': 0.8525943756103516}, {'name': 'model', 'confidence': 0.8428838849067688}, {'name': 'ground', 'confidence': 0.6431778073310852}, {'name': 'street', 'confidence': 0.5492902398109436}]}, 'objectsResult': {'values': [{'boundingBox': {'x': 124, 'y': 353, 'w': 162, 'h': 279}, 'tags': [{'name': 'Miniskirt', 'confidence': 0.73}]}, {'boundingBox': {'x': 109, 'y': 83, 'w': 196, 'h': 463}, 'tags': [{'name': 'person', 'confidence': 0.528}]}]}, 'readResult': {'blocks': []}, 'peopleResult': {'values': [{'boundingBox': {'x': 111, 'y': 73, 'w': 188, 'h': 726}, 'confidence': 0.9468265771865845}, {'boundingBox': {'x': 0, 'y': 336, 'w': 22, 'h': 162}, 'confidence': 0.007766443304717541}, {'boundingBox': {'x': 117, 'y': 331, 'w': 165, 'h': 214}, 'confidence': 0.0030558102298527956}]}}
Caption: a woman in a skirt and blouse (Confidence: 0.7034857869148254)
Tags:
- clothing (Confidence: 0.9936479330062866)
- person (Confidence: 0.9903221130371094)
- fashion (Confidence: 0.9715772271156311)
- waist (Confidence: 0.9683555364608765)
- shoulder (Confidence: 0.9670990705490112)
- street fashion (Confidence: 0.9651206731796265)
- fashion model (Confidence: 0.9378894567489624)
- casual dress (Confidence: 0.9372140169143677)
- outdoor (Confidence: 0.9252172708511353)
- lady (Confidence: 0.9249401092529297)
- high heels (Confidence: 0.9158104658126831)
- fashion design (Confidence: 0.9150017499923706)
- blouse (Confidence: 0.9002287983894348)
- building (Confidence: 0.898080587387085)
- female person (Confidence: 0.8961195945739746)
- woman (Confidence: 0.895744800567627)
- fashion accessory (Confidence: 0.885344922542572)
- skirt (Confidence: 0.8756769299507141)
- day dress (Confidence: 0.8627912998199463)
- sleeve (Confidence: 0.8556791543960571)
- photo shoot (Confidence: 0.8525943756103516)
- model (Confidence: 0.8428838849067688)
- ground (Confidence: 0.6431778073310852)
- street (Confidence: 0.5492902398109436)
Dense Captions:
- a woman in a skirt and blouse (Confidence: 0.7034857869148254)
- a woman wearing a black skirt (Confidence: 0.8199406266212463)
- a close up of a woman's skirt (Confidence: 0.8041300773620605)
- a woman smiling with her hair blowing in the wind (Confidence: 0.772121012210846)
Analyzing image: D:\Dinesh\Tech\GitHub\virtual-assistant\images\resized_image\women\F 5.jpg
{'modelVersion': '2023-10-01', 'captionResult': {'text': 'a woman in a pink suit', 'confidence': 0.7960219383239746}, 'denseCaptionsResult': {'values': [{'text': 'a woman in a pink suit', 'confidence': 0.7960219383239746, 'boundingBox': {'x': 0, 'y': 0, 'w': 400, 'h': 800}}, {'text': 'a woman wearing a pink skirt', 'confidence': 0.7349811792373657, 'boundingBox': {'x': 115, 'y': 19, 'w': 170, 'h': 766}}, {'text': 'a woman with long hair', 'confidence': 0.6577296257019043, 'boundingBox': {'x': 174, 'y': 20, 'w': 76, 'h': 111}}, {'text': "a close up of a person's feet", 'confidence': 0.7982906699180603, 'boundingBox': {'x': 169, 'y': 738, 'w': 91, 'h': 58}}]}, 'metadata': {'width': 400, 'height': 800}, 'tagsResult': {'values': [{'name': 'clothing', 'confidence': 0.99587082862854}, {'name': 'person', 'confidence': 0.9944287538528442}, {'name': 'fashion design', 'confidence': 0.9289777278900146}, {'name': 'fashion', 'confidence': 0.9261701107025146}, {'name': 'shoulder', 'confidence': 0.9104946851730347}, {'name': 'casual dress', 'confidence': 0.8990424871444702}, {'name': 'day dress', 'confidence': 0.8989772796630859}, {'name': 'waist', 'confidence': 0.8984031081199646}, {'name': 'collar', 'confidence': 0.8864355683326721}, {'name': 'standing', 'confidence': 0.8857401609420776}, {'name': 'pattern (fashion design)', 'confidence': 0.8769408464431763}, {'name': 'blazer', 'confidence': 0.8715298175811768}, {'name': 'blouse', 'confidence': 0.8648285865783691}, {'name': 'sleeve', 'confidence': 0.8639148473739624}, {'name': 'fashion model', 'confidence': 0.8608281016349792}, {'name': 'skirt', 'confidence': 0.8485586643218994}, {'name': 'sheath dress', 'confidence': 0.8476399183273315}, {'name': 'cocktail dress', 'confidence': 0.8400048017501831}, {'name': 'woman', 'confidence': 0.7902947068214417}, {'name': 'wearing', 'confidence': 0.7073326706886292}, {'name': 'dress', 'confidence': 0.6546826958656311}]}, 'objectsResult': {'values': []}, 'readResult': {'blocks': []}, 'peopleResult': {'values': [{'boundingBox': {'x': 116, 'y': 21, 'w': 180, 'h': 775}, 'confidence': 0.9280736446380615}, {'boundingBox': {'x': 122, 'y': 300, 'w': 156, 'h': 198}, 'confidence': 0.0019110467983409762}]}}
Caption: a woman in a pink suit (Confidence: 0.7960219383239746)
Tags:
- clothing (Confidence: 0.99587082862854)
- person (Confidence: 0.9944287538528442)
- fashion design (Confidence: 0.9289777278900146)
- fashion (Confidence: 0.9261701107025146)
- shoulder (Confidence: 0.9104946851730347)
- casual dress (Confidence: 0.8990424871444702)
- day dress (Confidence: 0.8989772796630859)
- waist (Confidence: 0.8984031081199646)
- collar (Confidence: 0.8864355683326721)
- standing (Confidence: 0.8857401609420776)
- pattern (fashion design) (Confidence: 0.8769408464431763)
- blazer (Confidence: 0.8715298175811768)
- blouse (Confidence: 0.8648285865783691)
- sleeve (Confidence: 0.8639148473739624)
- fashion model (Confidence: 0.8608281016349792)
- skirt (Confidence: 0.8485586643218994)
- sheath dress (Confidence: 0.8476399183273315)
- cocktail dress (Confidence: 0.8400048017501831)
- woman (Confidence: 0.7902947068214417)
- wearing (Confidence: 0.7073326706886292)
- dress (Confidence: 0.6546826958656311)
Dense Captions:
- a woman in a pink suit (Confidence: 0.7960219383239746)
- a woman wearing a pink skirt (Confidence: 0.7349811792373657)
- a woman with long hair (Confidence: 0.6577296257019043)
- a close up of a person's feet (Confidence: 0.7982906699180603)
Analyzing image: D:\Dinesh\Tech\GitHub\virtual-assistant\images\resized_image\women\F 6.jpg
{'modelVersion': '2023-10-01', 'captionResult': {'text': 'a woman in a black dress and grey blazer', 'confidence': 0.7886706590652466}, 'denseCaptionsResult': {'values': [{'text': 'a woman in a black dress and grey blazer', 'confidence': 0.7886706590652466, 'boundingBox': {'x': 0, 'y': 0, 'w': 400, 'h': 800}}, {'text': 'a woman in a black dress and grey blazer', 'confidence': 0.8239507079124451, 'boundingBox': {'x': 97, 'y': 109, 'w': 212, 'h': 668}}, {'text': 'a person wearing a suit', 'confidence': 0.691598653793335, 'boundingBox': {'x': 94, 'y': 459, 'w': 53, 'h': 250}}, {'text': 'a person looking at a mirror', 'confidence': 0.6972936391830444, 'boundingBox': {'x': 273, 'y': 194, 'w': 121, 'h': 172}}, {'text': 'a woman in a black dress', 'confidence': 0.83590167760849, 'boundingBox': {'x': 105, 'y': 212, 'w': 198, 'h': 277}}, {'text': 'a close-up of a woman smiling', 'confidence': 0.8699545860290527, 'boundingBox': {'x': 149, 'y': 116, 'w': 91, 'h': 147}}, {'text': 'a pair of legs wearing black shoes', 'confidence': 0.7136432528495789, 'boundingBox': {'x': 163, 'y': 667, 'w': 120, 'h': 125}}]}, 'metadata': {'width': 400, 'height': 800}, 'tagsResult': {'values': [{'name': 'person', 'confidence': 0.9901076555252075}, {'name': 'clothing', 'confidence': 0.9810616970062256}, {'name': 'footwear', 'confidence': 0.9682590961456299}, {'name': 'indoor', 'confidence': 0.9631772041320801}, {'name': 'wall', 'confidence': 0.9586803913116455}, {'name': 'fashion design', 'confidence': 0.9347202181816101}, {'name': 'fashion', 'confidence': 0.9333932399749756}, {'name': 'coat', 'confidence': 0.9268296957015991}, {'name': 'high heels', 'confidence': 0.9254823923110962}, {'name': 'mirror', 'confidence': 0.9086154699325562}, {'name': 'woman', 'confidence': 0.9076292514801025}, {'name': 'fashion accessory', 'confidence': 0.8935544490814209}, {'name': 'fashion model', 'confidence': 0.8911568522453308}, {'name': 'handbag', 'confidence': 0.8843884468078613}, {'name': 'sandal', 'confidence': 0.8451749086380005}, {'name': 'floor', 'confidence': 0.790454089641571}, {'name': 'standing', 'confidence': 0.6919139623641968}, {'name': 'ground', 'confidence': 0.6208716034889221}, {'name': 'wearing', 'confidence': 0.5971503853797913}, {'name': 'hosiery', 'confidence': 0.5210577845573425}]}, 'objectsResult': {'values': []}, 'readResult': {'blocks': []}, 'peopleResult': {'values': [{'boundingBox': {'x': 104, 'y': 116, 'w': 207, 'h': 677}, 'confidence': 0.9533897638320923}, {'boundingBox': {'x': 384, 'y': 333, 'w': 15, 'h': 26}, 'confidence': 0.011775105260312557}, {'boundingBox': {'x': 111, 'y': 344, 'w': 185, 'h': 203}, 'confidence': 0.0036136056296527386}]}}
Caption: a woman in a black dress and grey blazer (Confidence: 0.7886706590652466)
Tags:
- person (Confidence: 0.9901076555252075)
- clothing (Confidence: 0.9810616970062256)
- footwear (Confidence: 0.9682590961456299)
- indoor (Confidence: 0.9631772041320801)
- wall (Confidence: 0.9586803913116455)
- fashion design (Confidence: 0.9347202181816101)
- fashion (Confidence: 0.9333932399749756)
- coat (Confidence: 0.9268296957015991)
- high heels (Confidence: 0.9254823923110962)
- mirror (Confidence: 0.9086154699325562)
- woman (Confidence: 0.9076292514801025)
- fashion accessory (Confidence: 0.8935544490814209)
- fashion model (Confidence: 0.8911568522453308)
- handbag (Confidence: 0.8843884468078613)
- sandal (Confidence: 0.8451749086380005)
- floor (Confidence: 0.790454089641571)
- standing (Confidence: 0.6919139623641968)
- ground (Confidence: 0.6208716034889221)
- wearing (Confidence: 0.5971503853797913)
- hosiery (Confidence: 0.5210577845573425)
Dense Captions:
- a woman in a black dress and grey blazer (Confidence: 0.7886706590652466)
- a woman in a black dress and grey blazer (Confidence: 0.8239507079124451)
- a person wearing a suit (Confidence: 0.691598653793335)
- a person looking at a mirror (Confidence: 0.6972936391830444)
- a woman in a black dress (Confidence: 0.83590167760849)
- a close-up of a woman smiling (Confidence: 0.8699545860290527)
- a pair of legs wearing black shoes (Confidence: 0.7136432528495789)
Analyzing image: D:\Dinesh\Tech\GitHub\virtual-assistant\images\resized_image\women\F 7.jpg
{'modelVersion': '2023-10-01', 'captionResult': {'text': 'a woman in a blue blazer and black dress', 'confidence': 0.791405200958252}, 'denseCaptionsResult': {'values': [{'text': 'a woman in a blue blazer and black dress', 'confidence': 0.7918416261672974, 'boundingBox': {'x': 0, 'y': 0, 'w': 400, 'h': 800}}, {'text': 'a woman wearing a blue dress', 'confidence': 0.7947093844413757, 'boundingBox': {'x': 125, 'y': 120, 'w': 141, 'h': 652}}, {'text': 'a close-up of a rug', 'confidence': 0.8663970232009888, 'boundingBox': {'x': 266, 'y': 603, 'w': 128, 'h': 190}}, {'text': 'a person wearing a blue jacket', 'confidence': 0.7696890830993652, 'boundingBox': {'x': 132, 'y': 212, 'w': 130, 'h': 331}}, {'text': 'a woman smiling for the camera', 'confidence': 0.726590096950531, 'boundingBox': {'x': 155, 'y': 121, 'w': 86, 'h': 142}}, {'text': 'a white wall with a shadow', 'confidence': 0.6459268927574158, 'boundingBox': {'x': 5, 'y': 0, 'w': 91, 'h': 646}}, {'text': "a woman's legs in high heels", 'confidence': 0.7339574098587036, 'boundingBox': {'x': 0, 'y': 539, 'w': 387, 'h': 249}}, {'text': 'a close up of a pair of heels', 'confidence': 0.7291746139526367, 'boundingBox': {'x': 175, 'y': 650, 'w': 81, 'h': 143}}]}, 'metadata': {'width': 400, 'height': 800}, 'tagsResult': {'values': [{'name': 'person', 'confidence': 0.9942096471786499}, {'name': 'wall', 'confidence': 0.9889839887619019}, {'name': 'indoor', 'confidence': 0.9884048104286194}, {'name': 'clothing', 'confidence': 0.9775516986846924}, {'name': 'shoulder', 'confidence': 0.9248461723327637}, {'name': 'fashion', 'confidence': 0.9161190986633301}, {'name': 'pattern (fashion design)', 'confidence': 0.9069229364395142}, {'name': 'floor', 'confidence': 0.9020605087280273}, {'name': 'footwear', 'confidence': 0.896198570728302}, {'name': 'fashion design', 'confidence': 0.883110761642456}, {'name': 'smile', 'confidence': 0.8712321519851685}, {'name': 'day dress', 'confidence': 0.8616887331008911}, {'name': 'waist', 'confidence': 0.8613712787628174}, {'name': 'outerwear', 'confidence': 0.860763430595398}, {'name': 'human face', 'confidence': 0.859147310256958}, {'name': 'sleeve', 'confidence': 0.8435180187225342}, {'name': 'woman', 'confidence': 0.8220993280410767}, {'name': 'standing', 'confidence': 0.7237094640731812}, {'name': 'dress', 'confidence': 0.6245272755622864}, {'name': 'outfit', 'confidence': 0.4060181975364685}]}, 'objectsResult': {'values': [{'boundingBox': {'x': 122, 'y': 129, 'w': 148, 'h': 460}, 'tags': [{'name': 'person', 'confidence': 0.703}]}]}, 'readResult': {'blocks': []}, 'peopleResult': {'values': [{'boundingBox': {'x': 127, 'y': 123, 'w': 146, 'h': 661}, 'confidence': 0.9382160305976868}, {'boundingBox': {'x': 132, 'y': 343, 'w': 133, 'h': 202}, 'confidence': 0.0012802467681467533}]}}
Caption: a woman in a blue blazer and black dress (Confidence: 0.791405200958252)
Tags:
- person (Confidence: 0.9942096471786499)
- wall (Confidence: 0.9889839887619019)
- indoor (Confidence: 0.9884048104286194)
- clothing (Confidence: 0.9775516986846924)
- shoulder (Confidence: 0.9248461723327637)
- fashion (Confidence: 0.9161190986633301)
- pattern (fashion design) (Confidence: 0.9069229364395142)
- floor (Confidence: 0.9020605087280273)
- footwear (Confidence: 0.896198570728302)
- fashion design (Confidence: 0.883110761642456)
- smile (Confidence: 0.8712321519851685)
- day dress (Confidence: 0.8616887331008911)
- waist (Confidence: 0.8613712787628174)
- outerwear (Confidence: 0.860763430595398)
- human face (Confidence: 0.859147310256958)
- sleeve (Confidence: 0.8435180187225342)
- woman (Confidence: 0.8220993280410767)
- standing (Confidence: 0.7237094640731812)
- dress (Confidence: 0.6245272755622864)
- outfit (Confidence: 0.4060181975364685)
Dense Captions:
- a woman in a blue blazer and black dress (Confidence: 0.7918416261672974)
- a woman wearing a blue dress (Confidence: 0.7947093844413757)
- a close-up of a rug (Confidence: 0.8663970232009888)
- a person wearing a blue jacket (Confidence: 0.7696890830993652)
- a woman smiling for the camera (Confidence: 0.726590096950531)
- a white wall with a shadow (Confidence: 0.6459268927574158)
- a woman's legs in high heels (Confidence: 0.7339574098587036)
- a close up of a pair of heels (Confidence: 0.7291746139526367)
Analyzing image: D:\Dinesh\Tech\GitHub\virtual-assistant\images\resized_image\women\F 8.jpg
{'modelVersion': '2023-10-01', 'captionResult': {'text': 'a woman standing in front of a dresser', 'confidence': 0.8605771660804749}, 'denseCaptionsResult': {'values': [{'text': 'a woman standing in front of a dresser', 'confidence': 0.8605771660804749, 'boundingBox': {'x': 0, 'y': 0, 'w': 400, 'h': 800}}, {'text': 'a woman in a black dress', 'confidence': 0.8366380929946899, 'boundingBox': {'x': 94, 'y': 90, 'w': 252, 'h': 699}}, {'text': 'a hand on a chair', 'confidence': 0.7409756779670715, 'boundingBox': {'x': 302, 'y': 408, 'w': 95, 'h': 181}}, {'text': 'a black frame with a drawing on it', 'confidence': 0.6826942563056946, 'boundingBox': {'x': 310, 'y': 181, 'w': 57, 'h': 108}}, {'text': "a blurry image of a person's face", 'confidence': 0.6825976371765137, 'boundingBox': {'x': 0, 'y': 0, 'w': 62, 'h': 322}}, {'text': 'a close up of a dresser', 'confidence': 0.7868629097938538, 'boundingBox': {'x': 0, 'y': 417, 'w': 210, 'h': 365}}, {'text': 'a lamp on a wall', 'confidence': 0.7273011803627014, 'boundingBox': {'x': 64, 'y': 239, 'w': 59, 'h': 189}}]}, 'metadata': {'width': 400, 'height': 800}, 'tagsResult': {'values': [{'name': 'person', 'confidence': 0.9971078634262085}, {'name': 'clothing', 'confidence': 0.9918461441993713}, {'name': 'wall', 'confidence': 0.9854812622070312}, {'name': 'indoor', 'confidence': 0.9830890893936157}, {'name': 'furniture', 'confidence': 0.9590304493904114}, {'name': 'drawer', 'confidence': 0.958135724067688}, {'name': 'chest of drawers', 'confidence': 0.9452892541885376}, {'name': 'woman', 'confidence': 0.9336910843849182}, {'name': 'shoulder', 'confidence': 0.9010082483291626}, {'name': 'cabinetry', 'confidence': 0.8911614418029785}, {'name': 'footwear', 'confidence': 0.886915922164917}, {'name': 'fashion accessory', 'confidence': 0.8855165243148804}, {'name': 'chest', 'confidence': 0.8820140361785889}, {'name': 'high heels', 'confidence': 0.8749518394470215}, {'name': 'fashion', 'confidence': 0.8745789527893066}, {'name': 'waist', 'confidence': 0.8521347045898438}, {'name': 'fashion design', 'confidence': 0.8516714572906494}, {'name': 'standing', 'confidence': 0.8103039860725403}, {'name': 'floor', 'confidence': 0.7409943342208862}, {'name': 'dress', 'confidence': 0.6496313810348511}, {'name': 'wearing', 'confidence': 0.5366871356964111}, {'name': 'wooden', 'confidence': 0.5351431965827942}]}, 'objectsResult': {'values': [{'boundingBox': {'x': 124, 'y': 111, 'w': 215, 'h': 498}, 'tags': [{'name': 'person', 'confidence': 0.808}]}]}, 'readResult': {'blocks': []}, 'peopleResult': {'values': [{'boundingBox': {'x': 97, 'y': 94, 'w': 263, 'h': 705}, 'confidence': 0.9478018283843994}, {'boundingBox': {'x': 124, 'y': 368, 'w': 213, 'h': 199}, 'confidence': 0.003296842100098729}, {'boundingBox': {'x': 320, 'y': 205, 'w': 41, 'h': 73}, 'confidence': 0.0012549527455121279}]}}
Caption: a woman standing in front of a dresser (Confidence: 0.8605771660804749)
Tags:
- person (Confidence: 0.9971078634262085)
- clothing (Confidence: 0.9918461441993713)
- wall (Confidence: 0.9854812622070312)
- indoor (Confidence: 0.9830890893936157)
- furniture (Confidence: 0.9590304493904114)
- drawer (Confidence: 0.958135724067688)
- chest of drawers (Confidence: 0.9452892541885376)
- woman (Confidence: 0.9336910843849182)
- shoulder (Confidence: 0.9010082483291626)
- cabinetry (Confidence: 0.8911614418029785)
- footwear (Confidence: 0.886915922164917)
- fashion accessory (Confidence: 0.8855165243148804)
- chest (Confidence: 0.8820140361785889)
- high heels (Confidence: 0.8749518394470215)
- fashion (Confidence: 0.8745789527893066)
- waist (Confidence: 0.8521347045898438)
- fashion design (Confidence: 0.8516714572906494)
- standing (Confidence: 0.8103039860725403)
- floor (Confidence: 0.7409943342208862)
- dress (Confidence: 0.6496313810348511)
- wearing (Confidence: 0.5366871356964111)
- wooden (Confidence: 0.5351431965827942)
Dense Captions:
- a woman standing in front of a dresser (Confidence: 0.8605771660804749)
- a woman in a black dress (Confidence: 0.8366380929946899)
- a hand on a chair (Confidence: 0.7409756779670715)
- a black frame with a drawing on it (Confidence: 0.6826942563056946)
- a blurry image of a person's face (Confidence: 0.6825976371765137)
- a close up of a dresser (Confidence: 0.7868629097938538)
- a lamp on a wall (Confidence: 0.7273011803627014)
Analyzing image: D:\Dinesh\Tech\GitHub\virtual-assistant\images\resized_image\women\F 9.jpg
{'modelVersion': '2023-10-01', 'captionResult': {'text': 'a woman in a brown jacket and black skirt', 'confidence': 0.7816101312637329}, 'denseCaptionsResult': {'values': [{'text': 'a woman in a brown jacket and black skirt', 'confidence': 0.7816101312637329, 'boundingBox': {'x': 0, 'y': 0, 'w': 400, 'h': 800}}, {'text': 'a woman wearing a black skirt', 'confidence': 0.8111545443534851, 'boundingBox': {'x': 103, 'y': 88, 'w': 182, 'h': 672}}, {'text': "a blurry image of a person's arm", 'confidence': 0.764485239982605, 'boundingBox': {'x': 79, 'y': 432, 'w': 55, 'h': 222}}, {'text': 'a woman wearing a black skirt', 'confidence': 0.7295424938201904, 'boundingBox': {'x': 129, 'y': 321, 'w': 118, 'h': 211}}, {'text': 'a woman wearing sunglasses smiling', 'confidence': 0.7680703401565552, 'boundingBox': {'x': 165, 'y': 92, 'w': 121, 'h': 184}}, {'text': 'a blurry image of a field of green plants', 'confidence': 0.6710941791534424, 'boundingBox': {'x': 269, 'y': 270, 'w': 127, 'h': 160}}, {'text': "a black purse on a person's hand", 'confidence': 0.7432492971420288, 'boundingBox': {'x': 51, 'y': 380, 'w': 103, 'h': 338}}]}, 'metadata': {'width': 400, 'height': 800}, 'tagsResult': {'values': [{'name': 'outdoor', 'confidence': 0.9901933670043945}, {'name': 'person', 'confidence': 0.9858798980712891}, {'name': 'fashion', 'confidence': 0.9683690071105957}, {'name': 'fashion accessory', 'confidence': 0.9656189680099487}, {'name': 'footwear', 'confidence': 0.9519913196563721}, {'name': 'clothing', 'confidence': 0.949988603591919}, {'name': 'street fashion', 'confidence': 0.9480686187744141}, {'name': 'high heels', 'confidence': 0.9367468953132629}, {'name': 'fashion model', 'confidence': 0.9364528656005859}, {'name': 'waist', 'confidence': 0.9321730136871338}, {'name': 'shoulder', 'confidence': 0.9227896928787231}, {'name': 'sandal', 'confidence': 0.9002746343612671}, {'name': 'casual dress', 'confidence': 0.8995646238327026}, {'name': 'day dress', 'confidence': 0.8924291133880615}, {'name': 'fashion design', 'confidence': 0.8795159459114075}, {'name': 'handbag', 'confidence': 0.8647733330726624}, {'name': 'woman', 'confidence': 0.857376217842102}, {'name': 'cocktail dress', 'confidence': 0.8526679277420044}, {'name': 'miniskirt', 'confidence': 0.8415197134017944}, {'name': 'outfit', 'confidence': 0.6914616823196411}, {'name': 'dress', 'confidence': 0.5941608548164368}, {'name': 'girl', 'confidence': 0.5880743265151978}, {'name': 'ground', 'confidence': 0.5754156112670898}, {'name': 'sunglasses', 'confidence': 0.5375186204910278}]}, 'objectsResult': {'values': [{'boundingBox': {'x': 180, 'y': 123, 'w': 49, 'h': 33}, 'tags': [{'name': 'Sunglasses', 'confidence': 0.501}]}, {'boundingBox': {'x': 127, 'y': 337, 'w': 128, 'h': 196}, 'tags': [{'name': 'Miniskirt', 'confidence': 0.708}]}]}, 'readResult': {'blocks': []}, 'peopleResult': {'values': [{'boundingBox': {'x': 112, 'y': 93, 'w': 181, 'h': 676}, 'confidence': 0.9425415992736816}, {'boundingBox': {'x': 118, 'y': 334, 'w': 164, 'h': 203}, 'confidence': 0.0031426239293068647}]}}
Caption: a woman in a brown jacket and black skirt (Confidence: 0.7816101312637329)
Tags:
- outdoor (Confidence: 0.9901933670043945)
- person (Confidence: 0.9858798980712891)
- fashion (Confidence: 0.9683690071105957)
- fashion accessory (Confidence: 0.9656189680099487)
- footwear (Confidence: 0.9519913196563721)
- clothing (Confidence: 0.949988603591919)
- street fashion (Confidence: 0.9480686187744141)
- high heels (Confidence: 0.9367468953132629)
- fashion model (Confidence: 0.9364528656005859)
- waist (Confidence: 0.9321730136871338)
- shoulder (Confidence: 0.9227896928787231)
- sandal (Confidence: 0.9002746343612671)
- casual dress (Confidence: 0.8995646238327026)
- day dress (Confidence: 0.8924291133880615)
- fashion design (Confidence: 0.8795159459114075)
- handbag (Confidence: 0.8647733330726624)
- woman (Confidence: 0.857376217842102)
- cocktail dress (Confidence: 0.8526679277420044)
- miniskirt (Confidence: 0.8415197134017944)
- outfit (Confidence: 0.6914616823196411)
- dress (Confidence: 0.5941608548164368)
- girl (Confidence: 0.5880743265151978)
- ground (Confidence: 0.5754156112670898)
- sunglasses (Confidence: 0.5375186204910278)
Dense Captions:
- a woman in a brown jacket and black skirt (Confidence: 0.7816101312637329)
- a woman wearing a black skirt (Confidence: 0.8111545443534851)
- a blurry image of a person's arm (Confidence: 0.764485239982605)
- a woman wearing a black skirt (Confidence: 0.7295424938201904)
- a woman wearing sunglasses smiling (Confidence: 0.7680703401565552)
- a blurry image of a field of green plants (Confidence: 0.6710941791534424)
- a black purse on a person's hand (Confidence: 0.7432492971420288)