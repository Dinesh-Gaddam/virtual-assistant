Analyzing image: D:\Dinesh\Tech\GitHub\virtual-assistant\images\American\resized_images\women\Run1\resized_images\F_1.jpg
{'modelVersion': '2023-10-01', 'captionResult': {'text': 'a woman in a blue dress', 'confidence': 0.8804439902305603}, 'denseCaptionsResult': {'values': [{'text': 'a woman in a blue dress', 'confidence': 0.8804439902305603, 'boundingBox': {'x': 0, 'y': 0, 'w': 400, 'h': 800}}, {'text': 'a woman wearing a blue dress', 'confidence': 0.8130084872245789, 'boundingBox': {'x': 93, 'y': 25, 'w': 159, 'h': 757}}, {'text': 'a blurry image of a plant', 'confidence': 0.8195161819458008, 'boundingBox': {'x': 32, 'y': 164, 'w': 84, 'h': 228}}, {'text': 'a blurry image of a plant', 'confidence': 0.7601820826530457, 'boundingBox': {'x': 340, 'y': 165, 'w': 57, 'h': 254}}, {'text': 'a woman wearing a blue jacket', 'confidence': 0.7569583654403687, 'boundingBox': {'x': 143, 'y': 35, 'w': 123, 'h': 177}}]}, 'metadata': {'width': 400, 'height': 800}, 'tagsResult': {'values': [{'name': 'clothing', 'confidence': 0.9992886781692505}, {'name': 'person', 'confidence': 0.9831652641296387}, {'name': 'fashion', 'confidence': 0.971450686454773}, {'name': 'fashion design', 'confidence': 0.954893946647644}, {'name': 'fashion model', 'confidence': 0.9480499029159546}, {'name': 'day dress', 'confidence': 0.9210357666015625}, {'name': 'shoulder', 'confidence': 0.9145808219909668}, {'name': 'high heels', 'confidence': 0.9068188667297363}, {'name': 'footwear', 'confidence': 0.8796181678771973}, {'name': 'pattern (fashion design)', 'confidence': 0.8651552796363831}, {'name': 'fashion show', 'confidence': 0.8567705750465393}, {'name': 'lady', 'confidence': 0.8438880443572998}, {'name': 'haute couture', 'confidence': 0.8418262004852295}, {'name': 'indoor', 'confidence': 0.8003585934638977}, {'name': 'woman', 'confidence': 0.7872868776321411}, {'name': 'fabric', 'confidence': 0.7778888940811157}, {'name': 'blue', 'confidence': 0.7557581067085266}, {'name': 'wall', 'confidence': 0.7519873380661011}, {'name': 'floor', 'confidence': 0.692084550857544}, {'name': 'dress', 'confidence': 0.681490421295166}]}, 'objectsResult': {'values': []}, 'readResult': {'blocks': []}, 'peopleResult': {'values': [{'boundingBox': {'x': 95, 'y': 35, 'w': 173, 'h': 760}, 'confidence': 0.19061504304409027}, {'boundingBox': {'x': 113, 'y': 302, 'w': 146, 'h': 201}, 'confidence': 0.0010549298021942377}]}}
Caption: a woman in a blue dress (Confidence: 0.8804439902305603)
Tags:
- clothing (Confidence: 0.9992886781692505)
- person (Confidence: 0.9831652641296387)
- fashion (Confidence: 0.971450686454773)
- fashion design (Confidence: 0.954893946647644)
- fashion model (Confidence: 0.9480499029159546)
- day dress (Confidence: 0.9210357666015625)
- shoulder (Confidence: 0.9145808219909668)
- high heels (Confidence: 0.9068188667297363)
- footwear (Confidence: 0.8796181678771973)
- pattern (fashion design) (Confidence: 0.8651552796363831)
- fashion show (Confidence: 0.8567705750465393)
- lady (Confidence: 0.8438880443572998)
- haute couture (Confidence: 0.8418262004852295)
- indoor (Confidence: 0.8003585934638977)
- woman (Confidence: 0.7872868776321411)
- fabric (Confidence: 0.7778888940811157)
- blue (Confidence: 0.7557581067085266)
- wall (Confidence: 0.7519873380661011)
- floor (Confidence: 0.692084550857544)
- dress (Confidence: 0.681490421295166)
Dense Captions:
- a woman in a blue dress (Confidence: 0.8804439902305603)
- a woman wearing a blue dress (Confidence: 0.8130084872245789)
- a blurry image of a plant (Confidence: 0.8195161819458008)
- a blurry image of a plant (Confidence: 0.7601820826530457)
- a woman wearing a blue jacket (Confidence: 0.7569583654403687)
Analyzing image: D:\Dinesh\Tech\GitHub\virtual-assistant\images\American\resized_images\women\Run1\resized_images\F_10.jpg
{'modelVersion': '2023-10-01', 'captionResult': {'text': 'a woman in a red dress', 'confidence': 0.8708924055099487}, 'denseCaptionsResult': {'values': [{'text': 'a woman in a red dress', 'confidence': 0.8708924055099487, 'boundingBox': {'x': 0, 'y': 0, 'w': 400, 'h': 800}}, {'text': 'a woman in a red dress holding a purse', 'confidence': 0.8180763125419617, 'boundingBox': {'x': 93, 'y': 92, 'w': 175, 'h': 694}}, {'text': 'a close up of a bag', 'confidence': 0.7533065676689148, 'boundingBox': {'x': 168, 'y': 400, 'w': 58, 'h': 82}}, {'text': 'a close-up of a christmas tree', 'confidence': 0.8652535080909729, 'boundingBox': {'x': 0, 'y': 3, 'w': 138, 'h': 525}}, {'text': "a close up of a woman's feet", 'confidence': 0.7676438093185425, 'boundingBox': {'x': 181, 'y': 699, 'w': 57, 'h': 98}}, {'text': 'a close-up of a handbag', 'confidence': 0.8259629607200623, 'boundingBox': {'x': 160, 'y': 354, 'w': 78, 'h': 138}}, {'text': 'a woman with a pearl earring', 'confidence': 0.7156115174293518, 'boundingBox': {'x': 171, 'y': 103, 'w': 74, 'h': 106}}, {'text': "a close up of a person's hand", 'confidence': 0.7566566467285156, 'boundingBox': {'x': 189, 'y': 348, 'w': 65, 'h': 66}}]}, 'metadata': {'width': 400, 'height': 800}, 'tagsResult': {'values': [{'name': 'christmas tree', 'confidence': 0.9876245260238647}, {'name': 'clothing', 'confidence': 0.9666926264762878}, {'name': 'person', 'confidence': 0.9358536005020142}, {'name': 'christmas', 'confidence': 0.9012216329574585}, {'name': 'fashion', 'confidence': 0.8790127635002136}, {'name': 'woman', 'confidence': 0.8110399842262268}, {'name': 'dress', 'confidence': 0.7397493124008179}, {'name': 'red', 'confidence': 0.733142614364624}, {'name': 'indoor', 'confidence': 0.7316449284553528}, {'name': 'floor', 'confidence': 0.6470171809196472}, {'name': 'standing', 'confidence': 0.6257574558258057}, {'name': 'plant', 'confidence': 0.6064904928207397}]}, 'objectsResult': {'values': []}, 'readResult': {'blocks': []}, 'peopleResult': {'values': [{'boundingBox': {'x': 99, 'y': 107, 'w': 183, 'h': 691}, 'confidence': 0.9205418825149536}, {'boundingBox': {'x': 107, 'y': 372, 'w': 166, 'h': 199}, 'confidence': 0.0026920188684016466}]}}
Caption: a woman in a red dress (Confidence: 0.8708924055099487)
Tags:
- christmas tree (Confidence: 0.9876245260238647)
- clothing (Confidence: 0.9666926264762878)
- person (Confidence: 0.9358536005020142)
- christmas (Confidence: 0.9012216329574585)
- fashion (Confidence: 0.8790127635002136)
- woman (Confidence: 0.8110399842262268)
- dress (Confidence: 0.7397493124008179)
- red (Confidence: 0.733142614364624)
- indoor (Confidence: 0.7316449284553528)
- floor (Confidence: 0.6470171809196472)
- standing (Confidence: 0.6257574558258057)
- plant (Confidence: 0.6064904928207397)
Dense Captions:
- a woman in a red dress (Confidence: 0.8708924055099487)
- a woman in a red dress holding a purse (Confidence: 0.8180763125419617)
- a close up of a bag (Confidence: 0.7533065676689148)
- a close-up of a christmas tree (Confidence: 0.8652535080909729)
- a close up of a woman's feet (Confidence: 0.7676438093185425)
- a close-up of a handbag (Confidence: 0.8259629607200623)
- a woman with a pearl earring (Confidence: 0.7156115174293518)
- a close up of a person's hand (Confidence: 0.7566566467285156)
Analyzing image: D:\Dinesh\Tech\GitHub\virtual-assistant\images\American\resized_images\women\Run1\resized_images\F_11.jpg
{'modelVersion': '2023-10-01', 'captionResult': {'text': 'a woman standing in front of a white wall', 'confidence': 0.8714901804924011}, 'denseCaptionsResult': {'values': [{'text': 'a woman standing in front of a white wall', 'confidence': 0.8714901804924011, 'boundingBox': {'x': 0, 'y': 0, 'w': 400, 'h': 800}}, {'text': 'a woman wearing a blue shirt and white shorts', 'confidence': 0.7695636749267578, 'boundingBox': {'x': 141, 'y': 190, 'w': 145, 'h': 540}}, {'text': "a close up of a woman's waist", 'confidence': 0.754126787185669, 'boundingBox': {'x': 157, 'y': 380, 'w': 98, 'h': 121}}, {'text': 'a woman with a hand in her pocket', 'confidence': 0.7491388916969299, 'boundingBox': {'x': 139, 'y': 263, 'w': 142, 'h': 233}}, {'text': "a person's feet with brown toenails", 'confidence': 0.7098212838172913, 'boundingBox': {'x': 160, 'y': 657, 'w': 69, 'h': 101}}, {'text': 'a woman with long hair', 'confidence': 0.779208779335022, 'boundingBox': {'x': 164, 'y': 181, 'w': 85, 'h': 141}}, {'text': 'a woman standing in front of a white wall', 'confidence': 0.8556535243988037, 'boundingBox': {'x': 0, 'y': 0, 'w': 388, 'h': 640}}]}, 'metadata': {'width': 400, 'height': 800}, 'tagsResult': {'values': [{'name': 'clothing', 'confidence': 0.9937949776649475}, {'name': 'person', 'confidence': 0.9839099645614624}, {'name': 'wall', 'confidence': 0.9832321405410767}, {'name': 'human face', 'confidence': 0.9432544112205505}, {'name': 'shoulder', 'confidence': 0.9355468153953552}, {'name': 'footwear', 'confidence': 0.9237754344940186}, {'name': 'fashion', 'confidence': 0.923584520816803}, {'name': 'waist', 'confidence': 0.9215418696403503}, {'name': 'sandal', 'confidence': 0.9211342334747314}, {'name': 'fashion design', 'confidence': 0.9154194593429565}, {'name': 'day dress', 'confidence': 0.9056682586669922}, {'name': 'high heels', 'confidence': 0.8966624140739441}, {'name': 'blouse', 'confidence': 0.8761774301528931}, {'name': 'indoor', 'confidence': 0.8684285879135132}, {'name': 'fashion model', 'confidence': 0.8636276125907898}, {'name': 'joint', 'confidence': 0.8589683771133423}, {'name': 'casual dress', 'confidence': 0.8409060835838318}, {'name': 'woman', 'confidence': 0.7831000685691833}, {'name': 'standing', 'confidence': 0.7315313816070557}, {'name': 'dress', 'confidence': 0.6000102758407593}, {'name': 'wearing', 'confidence': 0.5385799407958984}]}, 'objectsResult': {'values': [{'boundingBox': {'x': 165, 'y': 382, 'w': 100, 'h': 124}, 'tags': [{'name': 'Miniskirt', 'confidence': 0.568}]}, {'boundingBox': {'x': 142, 'y': 193, 'w': 143, 'h': 500}, 'tags': [{'name': 'person', 'confidence': 0.691}]}]}, 'readResult': {'blocks': []}, 'peopleResult': {'values': [{'boundingBox': {'x': 141, 'y': 184, 'w': 149, 'h': 575}, 'confidence': 0.9463921189308167}, {'boundingBox': {'x': 151, 'y': 375, 'w': 139, 'h': 206}, 'confidence': 0.0014841316733509302}]}}
Caption: a woman standing in front of a white wall (Confidence: 0.8714901804924011)
Tags:
- clothing (Confidence: 0.9937949776649475)
- person (Confidence: 0.9839099645614624)
- wall (Confidence: 0.9832321405410767)
- human face (Confidence: 0.9432544112205505)
- shoulder (Confidence: 0.9355468153953552)
- footwear (Confidence: 0.9237754344940186)
- fashion (Confidence: 0.923584520816803)
- waist (Confidence: 0.9215418696403503)
- sandal (Confidence: 0.9211342334747314)
- fashion design (Confidence: 0.9154194593429565)
- day dress (Confidence: 0.9056682586669922)
- high heels (Confidence: 0.8966624140739441)
- blouse (Confidence: 0.8761774301528931)
- indoor (Confidence: 0.8684285879135132)
- fashion model (Confidence: 0.8636276125907898)
- joint (Confidence: 0.8589683771133423)
- casual dress (Confidence: 0.8409060835838318)
- woman (Confidence: 0.7831000685691833)
- standing (Confidence: 0.7315313816070557)
- dress (Confidence: 0.6000102758407593)
- wearing (Confidence: 0.5385799407958984)
Dense Captions:
- a woman standing in front of a white wall (Confidence: 0.8714901804924011)
- a woman wearing a blue shirt and white shorts (Confidence: 0.7695636749267578)
- a close up of a woman's waist (Confidence: 0.754126787185669)
- a woman with a hand in her pocket (Confidence: 0.7491388916969299)
- a person's feet with brown toenails (Confidence: 0.7098212838172913)
- a woman with long hair (Confidence: 0.779208779335022)
- a woman standing in front of a white wall (Confidence: 0.8556535243988037)
Analyzing image: D:\Dinesh\Tech\GitHub\virtual-assistant\images\American\resized_images\women\Run1\resized_images\F_12.jpg
{'modelVersion': '2023-10-01', 'captionResult': {'text': 'a woman wearing sunglasses and a skirt', 'confidence': 0.7680467367172241}, 'denseCaptionsResult': {'values': [{'text': 'a woman wearing sunglasses and a skirt', 'confidence': 0.7680467367172241, 'boundingBox': {'x': 0, 'y': 0, 'w': 400, 'h': 800}}, {'text': 'a woman in a skirt and a green shirt', 'confidence': 0.7352137565612793, 'boundingBox': {'x': 122, 'y': 183, 'w': 213, 'h': 604}}, {'text': 'a close up of a white skirt', 'confidence': 0.7458731532096863, 'boundingBox': {'x': 150, 'y': 422, 'w': 99, 'h': 176}}, {'text': 'a woman with long hair wearing sunglasses', 'confidence': 0.6929612159729004, 'boundingBox': {'x': 152, 'y': 190, 'w': 83, 'h': 158}}, {'text': 'a woman wearing a green top and white skirt', 'confidence': 0.7896580100059509, 'boundingBox': {'x': 124, 'y': 297, 'w': 178, 'h': 284}}, {'text': 'a close-up of a plant', 'confidence': 0.7646339535713196, 'boundingBox': {'x': 56, 'y': 374, 'w': 83, 'h': 130}}, {'text': 'a close up of a metal object', 'confidence': 0.6877428889274597, 'boundingBox': {'x': 299, 'y': 0, 'w': 95, 'h': 781}}, {'text': 'a woman wearing sunglasses and a skirt', 'confidence': 0.7600184082984924, 'boundingBox': {'x': 0, 'y': 0, 'w': 385, 'h': 790}}]}, 'metadata': {'width': 400, 'height': 800}, 'tagsResult': {'values': [{'name': 'clothing', 'confidence': 0.9925472140312195}, {'name': 'person', 'confidence': 0.9593212604522705}, {'name': 'outdoor', 'confidence': 0.9295374751091003}, {'name': 'building', 'confidence': 0.9152774214744568}, {'name': 'woman', 'confidence': 0.9083626866340637}, {'name': 'fashion accessory', 'confidence': 0.901688277721405}, {'name': 'footwear', 'confidence': 0.8918161392211914}, {'name': 'fashion', 'confidence': 0.8619606494903564}, {'name': 'waist', 'confidence': 0.861922025680542}, {'name': 'lady', 'confidence': 0.8465598821640015}, {'name': 'window', 'confidence': 0.7353109121322632}, {'name': 'girl', 'confidence': 0.6054539680480957}, {'name': 'standing', 'confidence': 0.5948991179466248}]}, 'objectsResult': {'values': []}, 'readResult': {'blocks': [{'lines': [{'text': '1/6', 'boundingPolygon': [{'x': 357, 'y': 21}, {'x': 380, 'y': 22}, {'x': 380, 'y': 44}, {'x': 356, 'y': 44}], 'words': [{'text': '1/6', 'boundingPolygon': [{'x': 356, 'y': 21}, {'x': 377, 'y': 21}, {'x': 377, 'y': 44}, {'x': 356, 'y': 43}], 'confidence': 0.965}]}]}]}, 'peopleResult': {'values': [{'boundingBox': {'x': 127, 'y': 194, 'w': 224, 'h': 605}, 'confidence': 0.7865033149719238}, {'boundingBox': {'x': 136, 'y': 377, 'w': 203, 'h': 224}, 'confidence': 0.0019430926768109202}]}}
Caption: a woman wearing sunglasses and a skirt (Confidence: 0.7680467367172241)
Tags:
- clothing (Confidence: 0.9925472140312195)
- person (Confidence: 0.9593212604522705)
- outdoor (Confidence: 0.9295374751091003)
- building (Confidence: 0.9152774214744568)
- woman (Confidence: 0.9083626866340637)
- fashion accessory (Confidence: 0.901688277721405)
- footwear (Confidence: 0.8918161392211914)
- fashion (Confidence: 0.8619606494903564)
- waist (Confidence: 0.861922025680542)
- lady (Confidence: 0.8465598821640015)
- window (Confidence: 0.7353109121322632)
- girl (Confidence: 0.6054539680480957)
- standing (Confidence: 0.5948991179466248)
Dense Captions:
- a woman wearing sunglasses and a skirt (Confidence: 0.7680467367172241)
- a woman in a skirt and a green shirt (Confidence: 0.7352137565612793)
- a close up of a white skirt (Confidence: 0.7458731532096863)
- a woman with long hair wearing sunglasses (Confidence: 0.6929612159729004)
- a woman wearing a green top and white skirt (Confidence: 0.7896580100059509)
- a close-up of a plant (Confidence: 0.7646339535713196)
- a close up of a metal object (Confidence: 0.6877428889274597)
- a woman wearing sunglasses and a skirt (Confidence: 0.7600184082984924)
Analyzing image: D:\Dinesh\Tech\GitHub\virtual-assistant\images\American\resized_images\women\Run1\resized_images\F_13.png
{'modelVersion': '2023-10-01', 'captionResult': {'text': 'a woman wearing a brown dress', 'confidence': 0.7996203899383545}, 'denseCaptionsResult': {'values': [{'text': 'a woman wearing a brown dress', 'confidence': 0.7996203899383545, 'boundingBox': {'x': 0, 'y': 0, 'w': 400, 'h': 800}}, {'text': 'a woman wearing a brown dress', 'confidence': 0.7318982481956482, 'boundingBox': {'x': 92, 'y': 0, 'w': 176, 'h': 777}}, {'text': 'a close-up of a woman', 'confidence': 0.9193321466445923, 'boundingBox': {'x': 146, 'y': 14, 'w': 112, 'h': 181}}, {'text': "a close-up of a woman's feet", 'confidence': 0.8628923296928406, 'boundingBox': {'x': 156, 'y': 625, 'w': 60, 'h': 158}}, {'text': 'a close up of a dress', 'confidence': 0.7889321446418762, 'boundingBox': {'x': 108, 'y': 279, 'w': 150, 'h': 319}}, {'text': 'a blurry green bush', 'confidence': 0.668538510799408, 'boundingBox': {'x': 268, 'y': 263, 'w': 62, 'h': 81}}, {'text': 'blur a blurry image of a tree', 'confidence': 0.748283326625824, 'boundingBox': {'x': 270, 'y': 0, 'w': 123, 'h': 270}}, {'text': 'a woman wearing a brown skirt and sandals', 'confidence': 0.7244333624839783, 'boundingBox': {'x': 0, 'y': 289, 'w': 388, 'h': 496}}, {'text': 'a close up of a leg', 'confidence': 0.7041520476341248, 'boundingBox': {'x': 174, 'y': 622, 'w': 51, 'h': 87}}, {'text': 'a woman wearing a brown dress', 'confidence': 0.7331585884094238, 'boundingBox': {'x': 99, 'y': 9, 'w': 181, 'h': 394}}]}, 'metadata': {'width': 400, 'height': 800}, 'tagsResult': {'values': [{'name': 'clothing', 'confidence': 0.9944460391998291}, {'name': 'fashion', 'confidence': 0.9714424014091492}, {'name': 'person', 'confidence': 0.9660764932632446}, {'name': 'day dress', 'confidence': 0.9639536738395691}, {'name': 'fashion model', 'confidence': 0.9595026969909668}, {'name': 'fashion design', 'confidence': 0.9563249349594116}, {'name': 'pattern (fashion design)', 'confidence': 0.955929160118103}, {'name': 'footwear', 'confidence': 0.9097524881362915}, {'name': 'polka dot', 'confidence': 0.8922989368438721}, {'name': 'casual dress', 'confidence': 0.8848531246185303}, {'name': 'cocktail dress', 'confidence': 0.8822378516197205}, {'name': 'photo shoot', 'confidence': 0.8765221238136292}, {'name': 'model', 'confidence': 0.8754985332489014}, {'name': 'waist', 'confidence': 0.8754206895828247}, {'name': 'dress', 'confidence': 0.8662847280502319}, {'name': 'shoulder', 'confidence': 0.8603095412254333}, {'name': 'sandal', 'confidence': 0.857479453086853}, {'name': 'fashion show', 'confidence': 0.8407131433486938}, {'name': 'outdoor', 'confidence': 0.7020701169967651}, {'name': 'standing', 'confidence': 0.6811429858207703}, {'name': 'woman', 'confidence': 0.582347571849823}]}, 'objectsResult': {'values': []}, 'readResult': {'blocks': []}, 'peopleResult': {'values': [{'boundingBox': {'x': 98, 'y': 7, 'w': 179, 'h': 785}, 'confidence': 0.9181420803070068}, {'boundingBox': {'x': 107, 'y': 294, 'w': 162, 'h': 201}, 'confidence': 0.0017102111596614122}]}}
Caption: a woman wearing a brown dress (Confidence: 0.7996203899383545)
Tags:
- clothing (Confidence: 0.9944460391998291)
- fashion (Confidence: 0.9714424014091492)
- person (Confidence: 0.9660764932632446)
- day dress (Confidence: 0.9639536738395691)
- fashion model (Confidence: 0.9595026969909668)
- fashion design (Confidence: 0.9563249349594116)
- pattern (fashion design) (Confidence: 0.955929160118103)
- footwear (Confidence: 0.9097524881362915)
- polka dot (Confidence: 0.8922989368438721)
- casual dress (Confidence: 0.8848531246185303)
- cocktail dress (Confidence: 0.8822378516197205)
- photo shoot (Confidence: 0.8765221238136292)
- model (Confidence: 0.8754985332489014)
- waist (Confidence: 0.8754206895828247)
- dress (Confidence: 0.8662847280502319)
- shoulder (Confidence: 0.8603095412254333)
- sandal (Confidence: 0.857479453086853)
- fashion show (Confidence: 0.8407131433486938)
- outdoor (Confidence: 0.7020701169967651)
- standing (Confidence: 0.6811429858207703)
- woman (Confidence: 0.582347571849823)
Dense Captions:
- a woman wearing a brown dress (Confidence: 0.7996203899383545)
- a woman wearing a brown dress (Confidence: 0.7318982481956482)
- a close-up of a woman (Confidence: 0.9193321466445923)
- a close-up of a woman's feet (Confidence: 0.8628923296928406)
- a close up of a dress (Confidence: 0.7889321446418762)
- a blurry green bush (Confidence: 0.668538510799408)
- blur a blurry image of a tree (Confidence: 0.748283326625824)
- a woman wearing a brown skirt and sandals (Confidence: 0.7244333624839783)
- a close up of a leg (Confidence: 0.7041520476341248)
- a woman wearing a brown dress (Confidence: 0.7331585884094238)
Analyzing image: D:\Dinesh\Tech\GitHub\virtual-assistant\images\American\resized_images\women\Run1\resized_images\F_14.png
{'modelVersion': '2023-10-01', 'captionResult': {'text': 'a woman wearing a blue dress', 'confidence': 0.8691132664680481}, 'denseCaptionsResult': {'values': [{'text': 'a woman wearing a blue dress', 'confidence': 0.8691132664680481, 'boundingBox': {'x': 0, 'y': 0, 'w': 400, 'h': 800}}, {'text': 'a woman wearing a blue dress', 'confidence': 0.8528799414634705, 'boundingBox': {'x': 84, 'y': 0, 'w': 209, 'h': 785}}, {'text': 'a close up of a bag', 'confidence': 0.847114086151123, 'boundingBox': {'x': 64, 'y': 478, 'w': 66, 'h': 208}}, {'text': 'a woman with long brown hair', 'confidence': 0.7906026244163513, 'boundingBox': {'x': 131, 'y': 9, 'w': 124, 'h': 218}}, {'text': 'a woman wearing a blue dress', 'confidence': 0.7932541966438293, 'boundingBox': {'x': 114, 'y': 318, 'w': 178, 'h': 311}}, {'text': 'a blurry picture of a window', 'confidence': 0.717437207698822, 'boundingBox': {'x': 1, 'y': 2, 'w': 107, 'h': 284}}, {'text': 'a close up of a foot', 'confidence': 0.7826892137527466, 'boundingBox': {'x': 163, 'y': 719, 'w': 55, 'h': 79}}, {'text': 'a woman wearing a blue dress and sandals holding a brown bag', 'confidence': 0.7409933805465698, 'boundingBox': {'x': 0, 'y': 423, 'w': 388, 'h': 366}}, {'text': 'a person standing in front of a bush', 'confidence': 0.7797672748565674, 'boundingBox': {'x': 268, 'y': 291, 'w': 126, 'h': 159}}, {'text': 'a close up of a bag', 'confidence': 0.8011611104011536, 'boundingBox': {'x': 45, 'y': 455, 'w': 104, 'h': 287}}]}, 'metadata': {'width': 400, 'height': 800}, 'tagsResult': {'values': [{'name': 'clothing', 'confidence': 0.9941908121109009}, {'name': 'person', 'confidence': 0.9916039705276489}, {'name': 'dress', 'confidence': 0.9753078818321228}, {'name': 'fashion', 'confidence': 0.9712661504745483}, {'name': 'day dress', 'confidence': 0.9664942026138306}, {'name': 'fashion design', 'confidence': 0.94410240650177}, {'name': 'shoulder', 'confidence': 0.9342482089996338}, {'name': 'waist', 'confidence': 0.9271707534790039}, {'name': 'street fashion', 'confidence': 0.9244189262390137}, {'name': 'casual dress', 'confidence': 0.9234451055526733}, {'name': 'pattern (fashion design)', 'confidence': 0.9201693534851074}, {'name': 'handbag', 'confidence': 0.911948025226593}, {'name': 'fashion model', 'confidence': 0.9077636003494263}, {'name': 'cocktail dress', 'confidence': 0.8979761600494385}, {'name': 'woman', 'confidence': 0.8847976922988892}, {'name': 'fashion accessory', 'confidence': 0.8819758296012878}, {'name': 'lady', 'confidence': 0.8737606406211853}, {'name': 'female person', 'confidence': 0.8566533327102661}, {'name': 'blouse', 'confidence': 0.8499457836151123}, {'name': 'outdoor', 'confidence': 0.794875979423523}, {'name': 'ground', 'confidence': 0.7735491394996643}, {'name': 'girl', 'confidence': 0.5260487794876099}]}, 'objectsResult': {'values': [{'boundingBox': {'x': 72, 'y': 473, 'w': 62, 'h': 204}, 'tags': [{'name': 'handbag', 'confidence': 0.682}]}]}, 'readResult': {'blocks': []}, 'peopleResult': {'values': [{'boundingBox': {'x': 96, 'y': 13, 'w': 204, 'h': 786}, 'confidence': 0.9562084078788757}, {'boundingBox': {'x': 103, 'y': 303, 'w': 181, 'h': 194}, 'confidence': 0.0023609481286257505}]}}
Caption: a woman wearing a blue dress (Confidence: 0.8691132664680481)
Tags:
- clothing (Confidence: 0.9941908121109009)
- person (Confidence: 0.9916039705276489)
- dress (Confidence: 0.9753078818321228)
- fashion (Confidence: 0.9712661504745483)
- day dress (Confidence: 0.9664942026138306)
- fashion design (Confidence: 0.94410240650177)
- shoulder (Confidence: 0.9342482089996338)
- waist (Confidence: 0.9271707534790039)
- street fashion (Confidence: 0.9244189262390137)
- casual dress (Confidence: 0.9234451055526733)
- pattern (fashion design) (Confidence: 0.9201693534851074)
- handbag (Confidence: 0.911948025226593)
- fashion model (Confidence: 0.9077636003494263)
- cocktail dress (Confidence: 0.8979761600494385)
- woman (Confidence: 0.8847976922988892)
- fashion accessory (Confidence: 0.8819758296012878)
- lady (Confidence: 0.8737606406211853)
- female person (Confidence: 0.8566533327102661)
- blouse (Confidence: 0.8499457836151123)
- outdoor (Confidence: 0.794875979423523)
- ground (Confidence: 0.7735491394996643)
- girl (Confidence: 0.5260487794876099)
Dense Captions:
- a woman wearing a blue dress (Confidence: 0.8691132664680481)
- a woman wearing a blue dress (Confidence: 0.8528799414634705)
- a close up of a bag (Confidence: 0.847114086151123)
- a woman with long brown hair (Confidence: 0.7906026244163513)
- a woman wearing a blue dress (Confidence: 0.7932541966438293)
- a blurry picture of a window (Confidence: 0.717437207698822)
- a close up of a foot (Confidence: 0.7826892137527466)
- a woman wearing a blue dress and sandals holding a brown bag (Confidence: 0.7409933805465698)
- a person standing in front of a bush (Confidence: 0.7797672748565674)
- a close up of a bag (Confidence: 0.8011611104011536)
Analyzing image: D:\Dinesh\Tech\GitHub\virtual-assistant\images\American\resized_images\women\Run1\resized_images\F_15.jpg
{'modelVersion': '2023-10-01', 'captionResult': {'text': 'a woman wearing a dress', 'confidence': 0.767620861530304}, 'denseCaptionsResult': {'values': [{'text': 'a woman wearing a dress', 'confidence': 0.767620861530304, 'boundingBox': {'x': 0, 'y': 0, 'w': 400, 'h': 800}}, {'text': 'a mannequin wearing a dress', 'confidence': 0.8507770299911499, 'boundingBox': {'x': 90, 'y': 0, 'w': 219, 'h': 785}}, {'text': 'a black object with a white object in the middle', 'confidence': 0.6208256483078003, 'boundingBox': {'x': 82, 'y': 537, 'w': 92, 'h': 247}}]}, 'metadata': {'width': 400, 'height': 800}, 'tagsResult': {'values': [{'name': 'clothing', 'confidence': 0.995862603187561}, {'name': 'person', 'confidence': 0.9808655381202698}, {'name': 'fashion', 'confidence': 0.9716777801513672}, {'name': 'shoulder', 'confidence': 0.9553244709968567}, {'name': 'fashion design', 'confidence': 0.953970193862915}, {'name': 'waist', 'confidence': 0.9490103125572205}, {'name': 'casual dress', 'confidence': 0.942629337310791}, {'name': 'fashion model', 'confidence': 0.9373031854629517}, {'name': 'fashion accessory', 'confidence': 0.9167764186859131}, {'name': 'street fashion', 'confidence': 0.9086501002311707}, {'name': 'sleeve', 'confidence': 0.8979250192642212}, {'name': 'handbag', 'confidence': 0.8960253000259399}, {'name': 'standing', 'confidence': 0.8680335283279419}, {'name': 'high heels', 'confidence': 0.8586229085922241}, {'name': 'top', 'confidence': 0.8439357280731201}, {'name': 'woman', 'confidence': 0.7368322610855103}, {'name': 'wearing', 'confidence': 0.5736677050590515}]}, 'objectsResult': {'values': []}, 'readResult': {'blocks': []}, 'peopleResult': {'values': [{'boundingBox': {'x': 95, 'y': 0, 'w': 225, 'h': 799}, 'confidence': 0.8528985977172852}, {'boundingBox': {'x': 115, 'y': 302, 'w': 197, 'h': 192}, 'confidence': 0.0013672951608896255}]}}
Caption: a woman wearing a dress (Confidence: 0.767620861530304)
Tags:
- clothing (Confidence: 0.995862603187561)
- person (Confidence: 0.9808655381202698)
- fashion (Confidence: 0.9716777801513672)
- shoulder (Confidence: 0.9553244709968567)
- fashion design (Confidence: 0.953970193862915)
- waist (Confidence: 0.9490103125572205)
- casual dress (Confidence: 0.942629337310791)
- fashion model (Confidence: 0.9373031854629517)
- fashion accessory (Confidence: 0.9167764186859131)
- street fashion (Confidence: 0.9086501002311707)
- sleeve (Confidence: 0.8979250192642212)
- handbag (Confidence: 0.8960253000259399)
- standing (Confidence: 0.8680335283279419)
- high heels (Confidence: 0.8586229085922241)
- top (Confidence: 0.8439357280731201)
- woman (Confidence: 0.7368322610855103)
- wearing (Confidence: 0.5736677050590515)
Dense Captions:
- a woman wearing a dress (Confidence: 0.767620861530304)
- a mannequin wearing a dress (Confidence: 0.8507770299911499)
- a black object with a white object in the middle (Confidence: 0.6208256483078003)
Analyzing image: D:\Dinesh\Tech\GitHub\virtual-assistant\images\American\resized_images\women\Run1\resized_images\F_16.jpg
{'modelVersion': '2023-10-01', 'captionResult': {'text': 'a woman in a beige dress', 'confidence': 0.7097204923629761}, 'denseCaptionsResult': {'values': [{'text': 'a woman in a beige dress', 'confidence': 0.7097204923629761, 'boundingBox': {'x': 0, 'y': 0, 'w': 400, 'h': 800}}, {'text': 'a woman in a skirt and jacket', 'confidence': 0.6960616111755371, 'boundingBox': {'x': 29, 'y': 29, 'w': 245, 'h': 757}}, {'text': 'a woman with long black hair', 'confidence': 0.8291908502578735, 'boundingBox': {'x': 104, 'y': 27, 'w': 136, 'h': 164}}, {'text': 'a woman wearing a beige suit', 'confidence': 0.6825509667396545, 'boundingBox': {'x': 37, 'y': 131, 'w': 232, 'h': 232}}]}, 'metadata': {'width': 400, 'height': 800}, 'tagsResult': {'values': [{'name': 'clothing', 'confidence': 0.9972602128982544}, {'name': 'fashion design', 'confidence': 0.963530421257019}, {'name': 'fashion', 'confidence': 0.9631099700927734}, {'name': 'fashion model', 'confidence': 0.9584842920303345}, {'name': 'person', 'confidence': 0.9518681764602661}, {'name': 'waist', 'confidence': 0.9120492935180664}, {'name': 'high heels', 'confidence': 0.9084748029708862}, {'name': 'casual dress', 'confidence': 0.9057003259658813}, {'name': 'day dress', 'confidence': 0.8948171138763428}, {'name': 'shoulder', 'confidence': 0.8917347192764282}, {'name': 'dress', 'confidence': 0.8897440433502197}, {'name': 'pattern (fashion design)', 'confidence': 0.8869384527206421}, {'name': 'photo shoot', 'confidence': 0.8593350648880005}, {'name': 'sheath dress', 'confidence': 0.8558259010314941}, {'name': 'fashion show', 'confidence': 0.8483113646507263}, {'name': 'model', 'confidence': 0.8475570678710938}, {'name': 'woman', 'confidence': 0.6406131982803345}, {'name': 'fabric', 'confidence': 0.5480199456214905}]}, 'objectsResult': {'values': []}, 'readResult': {'blocks': []}, 'peopleResult': {'values': [{'boundingBox': {'x': 29, 'y': 26, 'w': 258, 'h': 765}, 'confidence': 0.950128436088562}, {'boundingBox': {'x': 43, 'y': 295, 'w': 221, 'h': 209}, 'confidence': 0.002667977474629879}]}}
Caption: a woman in a beige dress (Confidence: 0.7097204923629761)
Tags:
- clothing (Confidence: 0.9972602128982544)
- fashion design (Confidence: 0.963530421257019)
- fashion (Confidence: 0.9631099700927734)
- fashion model (Confidence: 0.9584842920303345)
- person (Confidence: 0.9518681764602661)
- waist (Confidence: 0.9120492935180664)
- high heels (Confidence: 0.9084748029708862)
- casual dress (Confidence: 0.9057003259658813)
- day dress (Confidence: 0.8948171138763428)
- shoulder (Confidence: 0.8917347192764282)
- dress (Confidence: 0.8897440433502197)
- pattern (fashion design) (Confidence: 0.8869384527206421)
- photo shoot (Confidence: 0.8593350648880005)
- sheath dress (Confidence: 0.8558259010314941)
- fashion show (Confidence: 0.8483113646507263)
- model (Confidence: 0.8475570678710938)
- woman (Confidence: 0.6406131982803345)
- fabric (Confidence: 0.5480199456214905)
Dense Captions:
- a woman in a beige dress (Confidence: 0.7097204923629761)
- a woman in a skirt and jacket (Confidence: 0.6960616111755371)
- a woman with long black hair (Confidence: 0.8291908502578735)
- a woman wearing a beige suit (Confidence: 0.6825509667396545)
Analyzing image: D:\Dinesh\Tech\GitHub\virtual-assistant\images\American\resized_images\women\Run1\resized_images\F_17.jpg
{'modelVersion': '2023-10-01', 'captionResult': {'text': 'a woman wearing a red dress', 'confidence': 0.9161517024040222}, 'denseCaptionsResult': {'values': [{'text': 'a woman wearing a red dress', 'confidence': 0.9157201051712036, 'boundingBox': {'x': 0, 'y': 0, 'w': 400, 'h': 800}}, {'text': 'a woman wearing a red dress', 'confidence': 0.9148845672607422, 'boundingBox': {'x': 0, 'y': 0, 'w': 387, 'h': 785}}, {'text': 'a close up of a bag', 'confidence': 0.8049901127815247, 'boundingBox': {'x': 9, 'y': 547, 'w': 101, 'h': 224}}, {'text': "a close up of a woman's neck", 'confidence': 0.8585164546966553, 'boundingBox': {'x': 76, 'y': 0, 'w': 201, 'h': 109}}, {'text': 'a necklace with a pink and white pendant', 'confidence': 0.6216142177581787, 'boundingBox': {'x': 139, 'y': 47, 'w': 68, 'h': 132}}]}, 'metadata': {'width': 400, 'height': 800}, 'tagsResult': {'values': [{'name': 'clothing', 'confidence': 0.9951098561286926}, {'name': 'person', 'confidence': 0.9904074668884277}, {'name': 'fashion', 'confidence': 0.9792625904083252}, {'name': 'day dress', 'confidence': 0.9741655588150024}, {'name': 'dress', 'confidence': 0.972741961479187}, {'name': 'fashion accessory', 'confidence': 0.9654363393783569}, {'name': 'fashion design', 'confidence': 0.9587016105651855}, {'name': 'cocktail dress', 'confidence': 0.9550453424453735}, {'name': 'fashion model', 'confidence': 0.9475044012069702}, {'name': 'shoulder', 'confidence': 0.9311147332191467}, {'name': 'waist', 'confidence': 0.9054537415504456}, {'name': 'casual dress', 'confidence': 0.8840087652206421}, {'name': 'sheath dress', 'confidence': 0.8786258697509766}, {'name': 'model', 'confidence': 0.8655201196670532}, {'name': 'lady', 'confidence': 0.8651233315467834}, {'name': 'pattern (fashion design)', 'confidence': 0.8629578351974487}, {'name': 'woman', 'confidence': 0.8353651762008667}, {'name': 'red', 'confidence': 0.7292051911354065}, {'name': 'wearing', 'confidence': 0.6393654346466064}, {'name': 'outdoor', 'confidence': 0.5365989804267883}]}, 'objectsResult': {'values': []}, 'readResult': {'blocks': []}, 'peopleResult': {'values': [{'boundingBox': {'x': 13, 'y': 0, 'w': 386, 'h': 799}, 'confidence': 0.9458864331245422}, {'boundingBox': {'x': 61, 'y': 301, 'w': 314, 'h': 192}, 'confidence': 0.002283751033246517}]}}
Caption: a woman wearing a red dress (Confidence: 0.9161517024040222)
Tags:
- clothing (Confidence: 0.9951098561286926)
- person (Confidence: 0.9904074668884277)
- fashion (Confidence: 0.9792625904083252)
- day dress (Confidence: 0.9741655588150024)
- dress (Confidence: 0.972741961479187)
- fashion accessory (Confidence: 0.9654363393783569)
- fashion design (Confidence: 0.9587016105651855)
- cocktail dress (Confidence: 0.9550453424453735)
- fashion model (Confidence: 0.9475044012069702)
- shoulder (Confidence: 0.9311147332191467)
- waist (Confidence: 0.9054537415504456)
- casual dress (Confidence: 0.8840087652206421)
- sheath dress (Confidence: 0.8786258697509766)
- model (Confidence: 0.8655201196670532)
- lady (Confidence: 0.8651233315467834)
- pattern (fashion design) (Confidence: 0.8629578351974487)
- woman (Confidence: 0.8353651762008667)
- red (Confidence: 0.7292051911354065)
- wearing (Confidence: 0.6393654346466064)
- outdoor (Confidence: 0.5365989804267883)
Dense Captions:
- a woman wearing a red dress (Confidence: 0.9157201051712036)
- a woman wearing a red dress (Confidence: 0.9148845672607422)
- a close up of a bag (Confidence: 0.8049901127815247)
- a close up of a woman's neck (Confidence: 0.8585164546966553)
- a necklace with a pink and white pendant (Confidence: 0.6216142177581787)
Analyzing image: D:\Dinesh\Tech\GitHub\virtual-assistant\images\American\resized_images\women\Run1\resized_images\F_18.png
{'modelVersion': '2023-10-01', 'captionResult': {'text': 'a woman in a brown suit', 'confidence': 0.8280320167541504}, 'denseCaptionsResult': {'values': [{'text': 'a woman in a brown suit', 'confidence': 0.8280320167541504, 'boundingBox': {'x': 0, 'y': 0, 'w': 400, 'h': 800}}, {'text': 'a woman wearing a brown suit', 'confidence': 0.8094870448112488, 'boundingBox': {'x': 61, 'y': 6, 'w': 258, 'h': 781}}, {'text': 'a black bag from a swinger', 'confidence': 0.740566074848175, 'boundingBox': {'x': 46, 'y': 581, 'w': 93, 'h': 216}}, {'text': 'a woman with brown hair and a tan jacket', 'confidence': 0.6619463562965393, 'boundingBox': {'x': 127, 'y': 17, 'w': 137, 'h': 250}}, {'text': 'a woman wearing a brown suit', 'confidence': 0.79485684633255, 'boundingBox': {'x': 78, 'y': 155, 'w': 238, 'h': 411}}, {'text': "a close up of a woman's legs", 'confidence': 0.8313166499137878, 'boundingBox': {'x': 106, 'y': 414, 'w': 178, 'h': 377}}, {'text': 'a white tile floor with a black and white line', 'confidence': 0.5724473595619202, 'boundingBox': {'x': 269, 'y': 596, 'w': 124, 'h': 193}}, {'text': 'a white wall with a brown frame', 'confidence': 0.6440222859382629, 'boundingBox': {'x': 178, 'y': 207, 'w': 56, 'h': 206}}, {'text': "a close-up of a person's arm", 'confidence': 0.8577914834022522, 'boundingBox': {'x': 0, 'y': 0, 'w': 122, 'h': 616}}, {'text': 'a woman in a brown suit', 'confidence': 0.737571656703949, 'boundingBox': {'x': 103, 'y': 17, 'w': 208, 'h': 375}}]}, 'metadata': {'width': 400, 'height': 800}, 'tagsResult': {'values': [{'name': 'clothing', 'confidence': 0.9993869662284851}, {'name': 'person', 'confidence': 0.994262158870697}, {'name': 'fashion', 'confidence': 0.9654619693756104}, {'name': 'coat', 'confidence': 0.9603779911994934}, {'name': 'outerwear', 'confidence': 0.9585750102996826}, {'name': 'fashion design', 'confidence': 0.9457031488418579}, {'name': 'pocket', 'confidence': 0.9388413429260254}, {'name': 'handbag', 'confidence': 0.9346979856491089}, {'name': 'fashion model', 'confidence': 0.9256037473678589}, {'name': 'blazer', 'confidence': 0.9238333106040955}, {'name': 'trousers', 'confidence': 0.910300076007843}, {'name': 'fashion accessory', 'confidence': 0.9095699787139893}, {'name': 'casual dress', 'confidence': 0.8826900720596313}, {'name': 'collar', 'confidence': 0.8802382946014404}, {'name': 'leather', 'confidence': 0.8802059888839722}, {'name': 'shoulder', 'confidence': 0.8778834342956543}, {'name': 'sleeve', 'confidence': 0.8734757900238037}, {'name': 'waist', 'confidence': 0.868071436882019}, {'name': 'street fashion', 'confidence': 0.8593877553939819}, {'name': 'button', 'confidence': 0.854934811592102}, {'name': 'trench coat', 'confidence': 0.8541783094406128}, {'name': 'top', 'confidence': 0.8479210138320923}, {'name': 'luggage and bags', 'confidence': 0.8436155319213867}, {'name': 'fabric', 'confidence': 0.8369635939598083}, {'name': 'woman', 'confidence': 0.784443199634552}, {'name': 'indoor', 'confidence': 0.7717373967170715}, {'name': 'tan', 'confidence': 0.6556092500686646}, {'name': 'standing', 'confidence': 0.6457912921905518}, {'name': 'floor', 'confidence': 0.5893416404724121}, {'name': 'wearing', 'confidence': 0.5824952125549316}, {'name': 'suit', 'confidence': 0.4180590808391571}]}, 'objectsResult': {'values': [{'boundingBox': {'x': 58, 'y': 576, 'w': 83, 'h': 219}, 'tags': [{'name': 'handbag', 'confidence': 0.586}]}]}, 'readResult': {'blocks': []}, 'peopleResult': {'values': [{'boundingBox': {'x': 83, 'y': 20, 'w': 240, 'h': 779}, 'confidence': 0.9569509625434875}, {'boundingBox': {'x': 92, 'y': 326, 'w': 218, 'h': 205}, 'confidence': 0.0030079027637839317}]}}
Caption: a woman in a brown suit (Confidence: 0.8280320167541504)
Tags:
- clothing (Confidence: 0.9993869662284851)
- person (Confidence: 0.994262158870697)
- fashion (Confidence: 0.9654619693756104)
- coat (Confidence: 0.9603779911994934)
- outerwear (Confidence: 0.9585750102996826)
- fashion design (Confidence: 0.9457031488418579)
- pocket (Confidence: 0.9388413429260254)
- handbag (Confidence: 0.9346979856491089)
- fashion model (Confidence: 0.9256037473678589)
- blazer (Confidence: 0.9238333106040955)
- trousers (Confidence: 0.910300076007843)
- fashion accessory (Confidence: 0.9095699787139893)
- casual dress (Confidence: 0.8826900720596313)
- collar (Confidence: 0.8802382946014404)
- leather (Confidence: 0.8802059888839722)
- shoulder (Confidence: 0.8778834342956543)
- sleeve (Confidence: 0.8734757900238037)
- waist (Confidence: 0.868071436882019)
- street fashion (Confidence: 0.8593877553939819)
- button (Confidence: 0.854934811592102)
- trench coat (Confidence: 0.8541783094406128)
- top (Confidence: 0.8479210138320923)
- luggage and bags (Confidence: 0.8436155319213867)
- fabric (Confidence: 0.8369635939598083)
- woman (Confidence: 0.784443199634552)
- indoor (Confidence: 0.7717373967170715)
- tan (Confidence: 0.6556092500686646)
- standing (Confidence: 0.6457912921905518)
- floor (Confidence: 0.5893416404724121)
- wearing (Confidence: 0.5824952125549316)
- suit (Confidence: 0.4180590808391571)
Dense Captions:
- a woman in a brown suit (Confidence: 0.8280320167541504)
- a woman wearing a brown suit (Confidence: 0.8094870448112488)
- a black bag from a swinger (Confidence: 0.740566074848175)
- a woman with brown hair and a tan jacket (Confidence: 0.6619463562965393)
- a woman wearing a brown suit (Confidence: 0.79485684633255)
- a close up of a woman's legs (Confidence: 0.8313166499137878)
- a white tile floor with a black and white line (Confidence: 0.5724473595619202)
- a white wall with a brown frame (Confidence: 0.6440222859382629)
- a close-up of a person's arm (Confidence: 0.8577914834022522)
- a woman in a brown suit (Confidence: 0.737571656703949)
Analyzing image: D:\Dinesh\Tech\GitHub\virtual-assistant\images\American\resized_images\women\Run1\resized_images\F_2.jpg
{'modelVersion': '2023-10-01', 'captionResult': {'text': 'a woman in a white dress', 'confidence': 0.8864009976387024}, 'denseCaptionsResult': {'values': [{'text': 'a woman in a white dress', 'confidence': 0.8864009976387024, 'boundingBox': {'x': 0, 'y': 0, 'w': 400, 'h': 800}}, {'text': 'a woman in a white dress', 'confidence': 0.888688862323761, 'boundingBox': {'x': 120, 'y': 27, 'w': 188, 'h': 761}}, {'text': 'a close up of a white object', 'confidence': 0.7208629250526428, 'boundingBox': {'x': 109, 'y': 451, 'w': 63, 'h': 217}}, {'text': 'a woman with blonde hair', 'confidence': 0.7765906453132629, 'boundingBox': {'x': 145, 'y': 26, 'w': 109, 'h': 168}}, {'text': 'a woman wearing a white skirt', 'confidence': 0.7915604114532471, 'boundingBox': {'x': 139, 'y': 283, 'w': 116, 'h': 279}}, {'text': "a close up of a woman's legs", 'confidence': 0.7792953848838806, 'boundingBox': {'x': 0, 'y': 648, 'w': 392, 'h': 143}}, {'text': 'a close up of a white surface', 'confidence': 0.6834165453910828, 'boundingBox': {'x': 200, 'y': 694, 'w': 196, 'h': 97}}]}, 'metadata': {'width': 400, 'height': 800}, 'tagsResult': {'values': [{'name': 'clothing', 'confidence': 0.9986934661865234}, {'name': 'fashion model', 'confidence': 0.9805846810340881}, {'name': 'fashion', 'confidence': 0.9764701128005981}, {'name': 'fashion design', 'confidence': 0.9697962999343872}, {'name': 'person', 'confidence': 0.9649460911750793}, {'name': 'shoulder', 'confidence': 0.9451214671134949}, {'name': 'high heels', 'confidence': 0.9379028081893921}, {'name': 'fashion show', 'confidence': 0.9341076612472534}, {'name': 'waist', 'confidence': 0.9200558662414551}, {'name': 'model', 'confidence': 0.9192517995834351}, {'name': 'footwear', 'confidence': 0.9183831810951233}, {'name': 'photo shoot', 'confidence': 0.9095937609672546}, {'name': 'day dress', 'confidence': 0.9085931181907654}, {'name': 'sandal', 'confidence': 0.8944541215896606}, {'name': 'runway', 'confidence': 0.8854551315307617}, {'name': 'casual dress', 'confidence': 0.880666971206665}, {'name': 'wall', 'confidence': 0.8680121898651123}, {'name': 'cocktail dress', 'confidence': 0.8651264905929565}, {'name': 'sheath dress', 'confidence': 0.8522499799728394}, {'name': 'haute couture', 'confidence': 0.8497970104217529}, {'name': 'dress', 'confidence': 0.6940029859542847}, {'name': 'indoor', 'confidence': 0.6744297742843628}, {'name': 'woman', 'confidence': 0.6555730700492859}, {'name': 'fabric', 'confidence': 0.5594304800033569}]}, 'objectsResult': {'values': []}, 'readResult': {'blocks': []}, 'peopleResult': {'values': [{'boundingBox': {'x': 128, 'y': 26, 'w': 189, 'h': 772}, 'confidence': 0.9304049015045166}, {'boundingBox': {'x': 142, 'y': 298, 'w': 168, 'h': 203}, 'confidence': 0.0018974720733240247}]}}
Caption: a woman in a white dress (Confidence: 0.8864009976387024)
Tags:
- clothing (Confidence: 0.9986934661865234)
- fashion model (Confidence: 0.9805846810340881)
- fashion (Confidence: 0.9764701128005981)
- fashion design (Confidence: 0.9697962999343872)
- person (Confidence: 0.9649460911750793)
- shoulder (Confidence: 0.9451214671134949)
- high heels (Confidence: 0.9379028081893921)
- fashion show (Confidence: 0.9341076612472534)
- waist (Confidence: 0.9200558662414551)
- model (Confidence: 0.9192517995834351)
- footwear (Confidence: 0.9183831810951233)
- photo shoot (Confidence: 0.9095937609672546)
- day dress (Confidence: 0.9085931181907654)
- sandal (Confidence: 0.8944541215896606)
- runway (Confidence: 0.8854551315307617)
- casual dress (Confidence: 0.880666971206665)
- wall (Confidence: 0.8680121898651123)
- cocktail dress (Confidence: 0.8651264905929565)
- sheath dress (Confidence: 0.8522499799728394)
- haute couture (Confidence: 0.8497970104217529)
- dress (Confidence: 0.6940029859542847)
- indoor (Confidence: 0.6744297742843628)
- woman (Confidence: 0.6555730700492859)
- fabric (Confidence: 0.5594304800033569)
Dense Captions:
- a woman in a white dress (Confidence: 0.8864009976387024)
- a woman in a white dress (Confidence: 0.888688862323761)
- a close up of a white object (Confidence: 0.7208629250526428)
- a woman with blonde hair (Confidence: 0.7765906453132629)
- a woman wearing a white skirt (Confidence: 0.7915604114532471)
- a close up of a woman's legs (Confidence: 0.7792953848838806)
- a close up of a white surface (Confidence: 0.6834165453910828)
Analyzing image: D:\Dinesh\Tech\GitHub\virtual-assistant\images\American\resized_images\women\Run1\resized_images\F_3.png
{'modelVersion': '2023-10-01', 'captionResult': {'text': 'a woman wearing a blue dress', 'confidence': 0.8764075636863708}, 'denseCaptionsResult': {'values': [{'text': 'a woman wearing a blue dress', 'confidence': 0.8764075636863708, 'boundingBox': {'x': 0, 'y': 0, 'w': 400, 'h': 800}}, {'text': 'a woman wearing a blue dress', 'confidence': 0.8327217102050781, 'boundingBox': {'x': 90, 'y': 0, 'w': 200, 'h': 786}}, {'text': 'a woman wearing a blue dress', 'confidence': 0.8606307506561279, 'boundingBox': {'x': 98, 'y': 132, 'w': 186, 'h': 400}}, {'text': 'a woman with brown hair', 'confidence': 0.7493699193000793, 'boundingBox': {'x': 146, 'y': 14, 'w': 120, 'h': 184}}, {'text': "a close up of a person's arm", 'confidence': 0.8078035712242126, 'boundingBox': {'x': 93, 'y': 151, 'w': 69, 'h': 320}}, {'text': 'a close up of a foot', 'confidence': 0.7328708171844482, 'boundingBox': {'x': 157, 'y': 676, 'w': 56, 'h': 120}}, {'text': 'a blurry image of a tree', 'confidence': 0.8456275463104248, 'boundingBox': {'x': 272, 'y': 0, 'w': 124, 'h': 157}}, {'text': 'a woman with long brown hair wearing a blue shirt', 'confidence': 0.7835777401924133, 'boundingBox': {'x': 109, 'y': 5, 'w': 186, 'h': 301}}, {'text': 'a woman wearing a blue dress', 'confidence': 0.7701810002326965, 'boundingBox': {'x': 113, 'y': 308, 'w': 166, 'h': 225}}, {'text': 'a woman wearing a blue dress and brown purse', 'confidence': 0.7651388049125671, 'boundingBox': {'x': 0, 'y': 269, 'w': 387, 'h': 519}}]}, 'metadata': {'width': 400, 'height': 800}, 'tagsResult': {'values': [{'name': 'clothing', 'confidence': 0.9972745180130005}, {'name': 'person', 'confidence': 0.9928367137908936}, {'name': 'day dress', 'confidence': 0.9490488767623901}, {'name': 'footwear', 'confidence': 0.946094274520874}, {'name': 'dress', 'confidence': 0.9421030282974243}, {'name': 'fashion', 'confidence': 0.9290869235992432}, {'name': 'casual dress', 'confidence': 0.9253028035163879}, {'name': 'street fashion', 'confidence': 0.9227240085601807}, {'name': 'shoulder', 'confidence': 0.922146201133728}, {'name': 'waist', 'confidence': 0.9070854187011719}, {'name': 'fashion design', 'confidence': 0.8897071480751038}, {'name': 'pattern (fashion design)', 'confidence': 0.876197338104248}, {'name': 'sandal', 'confidence': 0.8608630299568176}, {'name': 'fashion model', 'confidence': 0.8576446175575256}, {'name': 'cocktail dress', 'confidence': 0.8492273092269897}, {'name': 'woman', 'confidence': 0.8467689752578735}, {'name': 'outdoor', 'confidence': 0.8460165858268738}, {'name': 'blouse', 'confidence': 0.8414796590805054}, {'name': 'ground', 'confidence': 0.7051151990890503}, {'name': 'blue', 'confidence': 0.6363406181335449}, {'name': 'girl', 'confidence': 0.5726674199104309}, {'name': 'street', 'confidence': 0.48789331316947937}]}, 'objectsResult': {'values': [{'boundingBox': {'x': 113, 'y': 17, 'w': 185, 'h': 510}, 'tags': [{'name': 'person', 'confidence': 0.708}]}]}, 'readResult': {'blocks': []}, 'peopleResult': {'values': [{'boundingBox': {'x': 112, 'y': 12, 'w': 182, 'h': 787}, 'confidence': 0.9324010014533997}, {'boundingBox': {'x': 118, 'y': 303, 'w': 159, 'h': 193}, 'confidence': 0.001568453386425972}]}}
Caption: a woman wearing a blue dress (Confidence: 0.8764075636863708)
Tags:
- clothing (Confidence: 0.9972745180130005)
- person (Confidence: 0.9928367137908936)
- day dress (Confidence: 0.9490488767623901)
- footwear (Confidence: 0.946094274520874)
- dress (Confidence: 0.9421030282974243)
- fashion (Confidence: 0.9290869235992432)
- casual dress (Confidence: 0.9253028035163879)
- street fashion (Confidence: 0.9227240085601807)
- shoulder (Confidence: 0.922146201133728)
- waist (Confidence: 0.9070854187011719)
- fashion design (Confidence: 0.8897071480751038)
- pattern (fashion design) (Confidence: 0.876197338104248)
- sandal (Confidence: 0.8608630299568176)
- fashion model (Confidence: 0.8576446175575256)
- cocktail dress (Confidence: 0.8492273092269897)
- woman (Confidence: 0.8467689752578735)
- outdoor (Confidence: 0.8460165858268738)
- blouse (Confidence: 0.8414796590805054)
- ground (Confidence: 0.7051151990890503)
- blue (Confidence: 0.6363406181335449)
- girl (Confidence: 0.5726674199104309)
- street (Confidence: 0.48789331316947937)
Dense Captions:
- a woman wearing a blue dress (Confidence: 0.8764075636863708)
- a woman wearing a blue dress (Confidence: 0.8327217102050781)
- a woman wearing a blue dress (Confidence: 0.8606307506561279)
- a woman with brown hair (Confidence: 0.7493699193000793)
- a close up of a person's arm (Confidence: 0.8078035712242126)
- a close up of a foot (Confidence: 0.7328708171844482)
- a blurry image of a tree (Confidence: 0.8456275463104248)
- a woman with long brown hair wearing a blue shirt (Confidence: 0.7835777401924133)
- a woman wearing a blue dress (Confidence: 0.7701810002326965)
- a woman wearing a blue dress and brown purse (Confidence: 0.7651388049125671)
Analyzing image: D:\Dinesh\Tech\GitHub\virtual-assistant\images\American\resized_images\women\Run1\resized_images\F_4.png
{'modelVersion': '2023-10-01', 'captionResult': {'text': 'a woman wearing a green dress', 'confidence': 0.833340585231781}, 'denseCaptionsResult': {'values': [{'text': 'a woman wearing a green dress', 'confidence': 0.833340585231781, 'boundingBox': {'x': 0, 'y': 0, 'w': 400, 'h': 800}}, {'text': "a close up of a woman's body", 'confidence': 0.7985992431640625, 'boundingBox': {'x': 88, 'y': 0, 'w': 197, 'h': 786}}, {'text': 'a blurry image of a tree', 'confidence': 0.7742426991462708, 'boundingBox': {'x': 1, 'y': 8, 'w': 85, 'h': 309}}, {'text': 'a pair of tan heels', 'confidence': 0.6993755102157593, 'boundingBox': {'x': 152, 'y': 729, 'w': 135, 'h': 68}}, {'text': 'a woman with long hair', 'confidence': 0.732379674911499, 'boundingBox': {'x': 136, 'y': 16, 'w': 117, 'h': 194}}, {'text': "a blurry picture of a person's hand", 'confidence': 0.683834969997406, 'boundingBox': {'x': 328, 'y': 0, 'w': 67, 'h': 243}}, {'text': 'a close up of a dress', 'confidence': 0.796852707862854, 'boundingBox': {'x': 178, 'y': 298, 'w': 66, 'h': 52}}, {'text': 'a woman wearing a skirt and heels', 'confidence': 0.7283033132553101, 'boundingBox': {'x': 0, 'y': 432, 'w': 387, 'h': 357}}, {'text': "a close up of a woman's dress", 'confidence': 0.7718793749809265, 'boundingBox': {'x': 102, 'y': 295, 'w': 170, 'h': 301}}, {'text': 'a blurry image of a person', 'confidence': 0.7856195569038391, 'boundingBox': {'x': 0, 'y': 300, 'w': 111, 'h': 140}}]}, 'metadata': {'width': 400, 'height': 800}, 'tagsResult': {'values': [{'name': 'clothing', 'confidence': 0.9961115717887878}, {'name': 'person', 'confidence': 0.9809093475341797}, {'name': 'fashion', 'confidence': 0.9473564624786377}, {'name': 'day dress', 'confidence': 0.9429411888122559}, {'name': 'fashion design', 'confidence': 0.9371678829193115}, {'name': 'pattern (fashion design)', 'confidence': 0.9354206323623657}, {'name': 'dress', 'confidence': 0.9119091033935547}, {'name': 'casual dress', 'confidence': 0.897445023059845}, {'name': 'footwear', 'confidence': 0.8956830501556396}, {'name': 'sleeve', 'confidence': 0.8582527041435242}, {'name': 'fashion model', 'confidence': 0.8488249778747559}, {'name': 'woman', 'confidence': 0.8073955774307251}, {'name': 'ground', 'confidence': 0.7031102180480957}, {'name': 'standing', 'confidence': 0.6730610132217407}, {'name': 'outdoor', 'confidence': 0.6008553504943848}, {'name': 'wearing', 'confidence': 0.5603996515274048}, {'name': 'girl', 'confidence': 0.42381465435028076}, {'name': 'outfit', 'confidence': 0.4162232577800751}]}, 'objectsResult': {'values': []}, 'readResult': {'blocks': []}, 'peopleResult': {'values': [{'boundingBox': {'x': 100, 'y': 13, 'w': 192, 'h': 786}, 'confidence': 0.9487801194190979}, {'boundingBox': {'x': 111, 'y': 305, 'w': 174, 'h': 193}, 'confidence': 0.0020908606238663197}]}}
Caption: a woman wearing a green dress (Confidence: 0.833340585231781)
Tags:
- clothing (Confidence: 0.9961115717887878)
- person (Confidence: 0.9809093475341797)
- fashion (Confidence: 0.9473564624786377)
- day dress (Confidence: 0.9429411888122559)
- fashion design (Confidence: 0.9371678829193115)
- pattern (fashion design) (Confidence: 0.9354206323623657)
- dress (Confidence: 0.9119091033935547)
- casual dress (Confidence: 0.897445023059845)
- footwear (Confidence: 0.8956830501556396)
- sleeve (Confidence: 0.8582527041435242)
- fashion model (Confidence: 0.8488249778747559)
- woman (Confidence: 0.8073955774307251)
- ground (Confidence: 0.7031102180480957)
- standing (Confidence: 0.6730610132217407)
- outdoor (Confidence: 0.6008553504943848)
- wearing (Confidence: 0.5603996515274048)
- girl (Confidence: 0.42381465435028076)
- outfit (Confidence: 0.4162232577800751)
Dense Captions:
- a woman wearing a green dress (Confidence: 0.833340585231781)
- a close up of a woman's body (Confidence: 0.7985992431640625)
- a blurry image of a tree (Confidence: 0.7742426991462708)
- a pair of tan heels (Confidence: 0.6993755102157593)
- a woman with long hair (Confidence: 0.732379674911499)
- a blurry picture of a person's hand (Confidence: 0.683834969997406)
- a close up of a dress (Confidence: 0.796852707862854)
- a woman wearing a skirt and heels (Confidence: 0.7283033132553101)
- a close up of a woman's dress (Confidence: 0.7718793749809265)
- a blurry image of a person (Confidence: 0.7856195569038391)
Analyzing image: D:\Dinesh\Tech\GitHub\virtual-assistant\images\American\resized_images\women\Run1\resized_images\F_5.png
{'modelVersion': '2023-10-01', 'captionResult': {'text': 'a woman wearing a white shirt and blue jeans', 'confidence': 0.8249773979187012}, 'denseCaptionsResult': {'values': [{'text': 'a woman wearing a white shirt and blue jeans', 'confidence': 0.8249773979187012, 'boundingBox': {'x': 0, 'y': 0, 'w': 400, 'h': 800}}, {'text': 'a woman wearing a white shirt and blue jeans', 'confidence': 0.820788562297821, 'boundingBox': {'x': 67, 'y': 7, 'w': 261, 'h': 782}}, {'text': "a close up of a woman's jeans", 'confidence': 0.7668552398681641, 'boundingBox': {'x': 96, 'y': 443, 'w': 187, 'h': 350}}, {'text': "a close up of a person's arm", 'confidence': 0.8225800395011902, 'boundingBox': {'x': 256, 'y': 209, 'w': 74, 'h': 420}}, {'text': 'a woman with long brown hair', 'confidence': 0.7895137667655945, 'boundingBox': {'x': 110, 'y': 14, 'w': 166, 'h': 296}}, {'text': 'a woman wearing a white shirt', 'confidence': 0.8073359131813049, 'boundingBox': {'x': 108, 'y': 199, 'w': 169, 'h': 251}}, {'text': 'a woman wearing a necklace', 'confidence': 0.7638812065124512, 'boundingBox': {'x': 169, 'y': 196, 'w': 76, 'h': 86}}, {'text': 'a close up of a hand in a pocket', 'confidence': 0.7653058171272278, 'boundingBox': {'x': 220, 'y': 452, 'w': 56, 'h': 62}}]}, 'metadata': {'width': 400, 'height': 800}, 'tagsResult': {'values': [{'name': 'person', 'confidence': 0.9964268207550049}, {'name': 'clothing', 'confidence': 0.9949787855148315}, {'name': 'casual dress', 'confidence': 0.9613709449768066}, {'name': 'jeans', 'confidence': 0.9603912830352783}, {'name': 'street fashion', 'confidence': 0.9595016241073608}, {'name': 'denim', 'confidence': 0.9570446610450745}, {'name': 'pocket', 'confidence': 0.9499059319496155}, {'name': 'waist', 'confidence': 0.9393982887268066}, {'name': 'shoulder', 'confidence': 0.9392387270927429}, {'name': 'human face', 'confidence': 0.9230179786682129}, {'name': 'top', 'confidence': 0.9062833189964294}, {'name': 'fashion', 'confidence': 0.9010878205299377}, {'name': 'sleeve', 'confidence': 0.8991961479187012}, {'name': 'fashion accessory', 'confidence': 0.8735402822494507}, {'name': 'trousers', 'confidence': 0.8659889101982117}, {'name': 'collar', 'confidence': 0.864447832107544}, {'name': 'jean', 'confidence': 0.86353999376297}, {'name': 'photo shoot', 'confidence': 0.8552418947219849}, {'name': 'fashion design', 'confidence': 0.8525421619415283}, {'name': 'belt', 'confidence': 0.8512721061706543}, {'name': 'fashion model', 'confidence': 0.8415735960006714}, {'name': 'handbag', 'confidence': 0.840111255645752}, {'name': 'woman', 'confidence': 0.8207708597183228}, {'name': 'outdoor', 'confidence': 0.6876866817474365}, {'name': 'girl', 'confidence': 0.6668562889099121}, {'name': 'blouse', 'confidence': 0.6018127202987671}, {'name': 'street', 'confidence': 0.47250115871429443}]}, 'objectsResult': {'values': []}, 'readResult': {'blocks': []}, 'peopleResult': {'values': [{'boundingBox': {'x': 74, 'y': 15, 'w': 262, 'h': 783}, 'confidence': 0.9590182900428772}, {'boundingBox': {'x': 86, 'y': 325, 'w': 233, 'h': 203}, 'confidence': 0.002772001549601555}]}}
Caption: a woman wearing a white shirt and blue jeans (Confidence: 0.8249773979187012)
Tags:
- person (Confidence: 0.9964268207550049)
- clothing (Confidence: 0.9949787855148315)
- casual dress (Confidence: 0.9613709449768066)
- jeans (Confidence: 0.9603912830352783)
- street fashion (Confidence: 0.9595016241073608)
- denim (Confidence: 0.9570446610450745)
- pocket (Confidence: 0.9499059319496155)
- waist (Confidence: 0.9393982887268066)
- shoulder (Confidence: 0.9392387270927429)
- human face (Confidence: 0.9230179786682129)
- top (Confidence: 0.9062833189964294)
- fashion (Confidence: 0.9010878205299377)
- sleeve (Confidence: 0.8991961479187012)
- fashion accessory (Confidence: 0.8735402822494507)
- trousers (Confidence: 0.8659889101982117)
- collar (Confidence: 0.864447832107544)
- jean (Confidence: 0.86353999376297)
- photo shoot (Confidence: 0.8552418947219849)
- fashion design (Confidence: 0.8525421619415283)
- belt (Confidence: 0.8512721061706543)
- fashion model (Confidence: 0.8415735960006714)
- handbag (Confidence: 0.840111255645752)
- woman (Confidence: 0.8207708597183228)
- outdoor (Confidence: 0.6876866817474365)
- girl (Confidence: 0.6668562889099121)
- blouse (Confidence: 0.6018127202987671)
- street (Confidence: 0.47250115871429443)
Dense Captions:
- a woman wearing a white shirt and blue jeans (Confidence: 0.8249773979187012)
- a woman wearing a white shirt and blue jeans (Confidence: 0.820788562297821)
- a close up of a woman's jeans (Confidence: 0.7668552398681641)
- a close up of a person's arm (Confidence: 0.8225800395011902)
- a woman with long brown hair (Confidence: 0.7895137667655945)
- a woman wearing a white shirt (Confidence: 0.8073359131813049)
- a woman wearing a necklace (Confidence: 0.7638812065124512)
- a close up of a hand in a pocket (Confidence: 0.7653058171272278)
Analyzing image: D:\Dinesh\Tech\GitHub\virtual-assistant\images\American\resized_images\women\Run1\resized_images\F_6.png
{'modelVersion': '2023-10-01', 'captionResult': {'text': 'a woman in a brown dress', 'confidence': 0.8705564737319946}, 'denseCaptionsResult': {'values': [{'text': 'a woman in a brown dress', 'confidence': 0.8705564737319946, 'boundingBox': {'x': 0, 'y': 0, 'w': 400, 'h': 800}}, {'text': 'a woman wearing a brown dress', 'confidence': 0.8456539511680603, 'boundingBox': {'x': 73, 'y': 9, 'w': 223, 'h': 779}}, {'text': 'a blurry green plant', 'confidence': 0.6869519352912903, 'boundingBox': {'x': 0, 'y': 258, 'w': 68, 'h': 204}}, {'text': 'a close-up of a couch', 'confidence': 0.8573296666145325, 'boundingBox': {'x': 277, 'y': 364, 'w': 118, 'h': 348}}, {'text': 'a close up of a pillow', 'confidence': 0.8099033236503601, 'boundingBox': {'x': 315, 'y': 437, 'w': 81, 'h': 93}}, {'text': 'a table with a chair in the background', 'confidence': 0.6266690492630005, 'boundingBox': {'x': 1, 'y': 449, 'w': 74, 'h': 237}}, {'text': 'a woman with brown hair and brown eyes', 'confidence': 0.7054082155227661, 'boundingBox': {'x': 120, 'y': 15, 'w': 139, 'h': 255}}, {'text': "a close-up of a person's legs", 'confidence': 0.8492452502250671, 'boundingBox': {'x': 126, 'y': 670, 'w': 156, 'h': 126}}, {'text': 'a blurry picture of a stool', 'confidence': 0.7416636943817139, 'boundingBox': {'x': 0, 'y': 447, 'w': 73, 'h': 94}}, {'text': 'a table with a round top', 'confidence': 0.5791968703269958, 'boundingBox': {'x': 0, 'y': 516, 'w': 69, 'h': 110}}]}, 'metadata': {'width': 400, 'height': 800}, 'tagsResult': {'values': [{'name': 'clothing', 'confidence': 0.9959553480148315}, {'name': 'person', 'confidence': 0.989652156829834}, {'name': 'indoor', 'confidence': 0.9807457327842712}, {'name': 'furniture', 'confidence': 0.9758045077323914}, {'name': 'dress', 'confidence': 0.9582661390304565}, {'name': 'wall', 'confidence': 0.9411455392837524}, {'name': 'day dress', 'confidence': 0.9370676875114441}, {'name': 'pattern (fashion design)', 'confidence': 0.9235974550247192}, {'name': 'shoulder', 'confidence': 0.9136322736740112}, {'name': 'fashion', 'confidence': 0.8854346871376038}, {'name': 'chair', 'confidence': 0.8797444701194763}, {'name': 'fashion design', 'confidence': 0.874050498008728}, {'name': 'blouse', 'confidence': 0.8484407067298889}, {'name': 'woman', 'confidence': 0.7738350629806519}, {'name': 'floor', 'confidence': 0.7399076819419861}, {'name': 'standing', 'confidence': 0.6743842363357544}, {'name': 'girl', 'confidence': 0.5696935653686523}]}, 'objectsResult': {'values': []}, 'readResult': {'blocks': []}, 'peopleResult': {'values': [{'boundingBox': {'x': 81, 'y': 17, 'w': 224, 'h': 782}, 'confidence': 0.9481858015060425}, {'boundingBox': {'x': 92, 'y': 303, 'w': 197, 'h': 195}, 'confidence': 0.0023208982311189175}]}}
Caption: a woman in a brown dress (Confidence: 0.8705564737319946)
Tags:
- clothing (Confidence: 0.9959553480148315)
- person (Confidence: 0.989652156829834)
- indoor (Confidence: 0.9807457327842712)
- furniture (Confidence: 0.9758045077323914)
- dress (Confidence: 0.9582661390304565)
- wall (Confidence: 0.9411455392837524)
- day dress (Confidence: 0.9370676875114441)
- pattern (fashion design) (Confidence: 0.9235974550247192)
- shoulder (Confidence: 0.9136322736740112)
- fashion (Confidence: 0.8854346871376038)
- chair (Confidence: 0.8797444701194763)
- fashion design (Confidence: 0.874050498008728)
- blouse (Confidence: 0.8484407067298889)
- woman (Confidence: 0.7738350629806519)
- floor (Confidence: 0.7399076819419861)
- standing (Confidence: 0.6743842363357544)
- girl (Confidence: 0.5696935653686523)
Dense Captions:
- a woman in a brown dress (Confidence: 0.8705564737319946)
- a woman wearing a brown dress (Confidence: 0.8456539511680603)
- a blurry green plant (Confidence: 0.6869519352912903)
- a close-up of a couch (Confidence: 0.8573296666145325)
- a close up of a pillow (Confidence: 0.8099033236503601)
- a table with a chair in the background (Confidence: 0.6266690492630005)
- a woman with brown hair and brown eyes (Confidence: 0.7054082155227661)
- a close-up of a person's legs (Confidence: 0.8492452502250671)
- a blurry picture of a stool (Confidence: 0.7416636943817139)
- a table with a round top (Confidence: 0.5791968703269958)
Analyzing image: D:\Dinesh\Tech\GitHub\virtual-assistant\images\American\resized_images\women\Run1\resized_images\F_7.png
{'modelVersion': '2023-10-01', 'captionResult': {'text': 'a woman in a suit', 'confidence': 0.8017448782920837}, 'denseCaptionsResult': {'values': [{'text': 'a woman in a suit', 'confidence': 0.8017448782920837, 'boundingBox': {'x': 0, 'y': 0, 'w': 400, 'h': 800}}, {'text': 'a close-up of a woman in a suit', 'confidence': 0.8580416440963745, 'boundingBox': {'x': 79, 'y': 0, 'w': 210, 'h': 787}}, {'text': 'a close up of a black bag', 'confidence': 0.7984638214111328, 'boundingBox': {'x': 82, 'y': 477, 'w': 55, 'h': 159}}, {'text': 'a close-up of a woman', 'confidence': 0.9191253185272217, 'boundingBox': {'x': 140, 'y': 13, 'w': 108, 'h': 193}}, {'text': 'a woman wearing a black suit', 'confidence': 0.7188959717750549, 'boundingBox': {'x': 101, 'y': 139, 'w': 180, 'h': 303}}, {'text': "a close-up of a woman's legs", 'confidence': 0.8695151805877686, 'boundingBox': {'x': 119, 'y': 412, 'w': 133, 'h': 352}}, {'text': 'a blurry image of a person standing in front of a window', 'confidence': 0.7219365239143372, 'boundingBox': {'x': 272, 'y': 0, 'w': 120, 'h': 607}}, {'text': 'a woman wearing black pants and a black purse', 'confidence': 0.6796312928199768, 'boundingBox': {'x': 51, 'y': 407, 'w': 267, 'h': 386}}, {'text': 'a woman in a black suit', 'confidence': 0.7834845781326294, 'boundingBox': {'x': 101, 'y': 8, 'w': 193, 'h': 298}}, {'text': 'a blurry image of a window', 'confidence': 0.6812468767166138, 'boundingBox': {'x': 0, 'y': 0, 'w': 88, 'h': 480}}]}, 'metadata': {'width': 400, 'height': 800}, 'tagsResult': {'values': [{'name': 'clothing', 'confidence': 0.9987820386886597}, {'name': 'person', 'confidence': 0.9952689409255981}, {'name': 'fashion', 'confidence': 0.9709872603416443}, {'name': 'coat', 'confidence': 0.9707978963851929}, {'name': 'outerwear', 'confidence': 0.9551929235458374}, {'name': 'blazer', 'confidence': 0.954968273639679}, {'name': 'fashion design', 'confidence': 0.9427081942558289}, {'name': 'fashion model', 'confidence': 0.9148706197738647}, {'name': 'pocket', 'confidence': 0.9147913455963135}, {'name': 'shoulder', 'confidence': 0.9107784032821655}, {'name': 'collar', 'confidence': 0.9033019542694092}, {'name': 'handbag', 'confidence': 0.8955056667327881}, {'name': 'trousers', 'confidence': 0.8939933776855469}, {'name': 'fashion accessory', 'confidence': 0.8933538198471069}, {'name': 'casual dress', 'confidence': 0.8748111724853516}, {'name': 'pantsuit', 'confidence': 0.8681498765945435}, {'name': 'street fashion', 'confidence': 0.8661400675773621}, {'name': 'footwear', 'confidence': 0.8632116317749023}, {'name': 'suit trousers', 'confidence': 0.8605404496192932}, {'name': 'sleeve', 'confidence': 0.8602983355522156}, {'name': 'indoor', 'confidence': 0.8566731214523315}, {'name': 'formal wear', 'confidence': 0.8509125709533691}, {'name': 'waist', 'confidence': 0.8491692543029785}, {'name': 'woman', 'confidence': 0.8443436622619629}, {'name': 'high heels', 'confidence': 0.8404204845428467}, {'name': 'suit', 'confidence': 0.7910135984420776}, {'name': 'floor', 'confidence': 0.7667304277420044}, {'name': 'wall', 'confidence': 0.7116981744766235}, {'name': 'standing', 'confidence': 0.692202091217041}, {'name': 'wearing', 'confidence': 0.638501763343811}]}, 'objectsResult': {'values': [{'boundingBox': {'x': 87, 'y': 475, 'w': 53, 'h': 161}, 'tags': [{'name': 'Luggage and bags', 'confidence': 0.719}]}]}, 'readResult': {'blocks': []}, 'peopleResult': {'values': [{'boundingBox': {'x': 99, 'y': 12, 'w': 190, 'h': 787}, 'confidence': 0.9562032222747803}, {'boundingBox': {'x': 106, 'y': 302, 'w': 172, 'h': 195}, 'confidence': 0.0020256845746189356}]}}
Caption: a woman in a suit (Confidence: 0.8017448782920837)
Tags:
- clothing (Confidence: 0.9987820386886597)
- person (Confidence: 0.9952689409255981)
- fashion (Confidence: 0.9709872603416443)
- coat (Confidence: 0.9707978963851929)
- outerwear (Confidence: 0.9551929235458374)
- blazer (Confidence: 0.954968273639679)
- fashion design (Confidence: 0.9427081942558289)
- fashion model (Confidence: 0.9148706197738647)
- pocket (Confidence: 0.9147913455963135)
- shoulder (Confidence: 0.9107784032821655)
- collar (Confidence: 0.9033019542694092)
- handbag (Confidence: 0.8955056667327881)
- trousers (Confidence: 0.8939933776855469)
- fashion accessory (Confidence: 0.8933538198471069)
- casual dress (Confidence: 0.8748111724853516)
- pantsuit (Confidence: 0.8681498765945435)
- street fashion (Confidence: 0.8661400675773621)
- footwear (Confidence: 0.8632116317749023)
- suit trousers (Confidence: 0.8605404496192932)
- sleeve (Confidence: 0.8602983355522156)
- indoor (Confidence: 0.8566731214523315)
- formal wear (Confidence: 0.8509125709533691)
- waist (Confidence: 0.8491692543029785)
- woman (Confidence: 0.8443436622619629)
- high heels (Confidence: 0.8404204845428467)
- suit (Confidence: 0.7910135984420776)
- floor (Confidence: 0.7667304277420044)
- wall (Confidence: 0.7116981744766235)
- standing (Confidence: 0.692202091217041)
- wearing (Confidence: 0.638501763343811)
Dense Captions:
- a woman in a suit (Confidence: 0.8017448782920837)
- a close-up of a woman in a suit (Confidence: 0.8580416440963745)
- a close up of a black bag (Confidence: 0.7984638214111328)
- a close-up of a woman (Confidence: 0.9191253185272217)
- a woman wearing a black suit (Confidence: 0.7188959717750549)
- a close-up of a woman's legs (Confidence: 0.8695151805877686)
- a blurry image of a person standing in front of a window (Confidence: 0.7219365239143372)
- a woman wearing black pants and a black purse (Confidence: 0.6796312928199768)
- a woman in a black suit (Confidence: 0.7834845781326294)
- a blurry image of a window (Confidence: 0.6812468767166138)
Analyzing image: D:\Dinesh\Tech\GitHub\virtual-assistant\images\American\resized_images\women\Run1\resized_images\F_8.png
{'modelVersion': '2023-10-01', 'captionResult': {'text': 'a woman in a pink suit', 'confidence': 0.7796657681465149}, 'denseCaptionsResult': {'values': [{'text': 'a woman in a pink suit', 'confidence': 0.7796657681465149, 'boundingBox': {'x': 0, 'y': 0, 'w': 400, 'h': 800}}, {'text': "a close up of a woman's dress", 'confidence': 0.7212175726890564, 'boundingBox': {'x': 91, 'y': 0, 'w': 172, 'h': 788}}, {'text': 'a close up of a bag', 'confidence': 0.7956770062446594, 'boundingBox': {'x': 93, 'y': 507, 'w': 56, 'h': 197}}, {'text': "a close-up of a woman's face", 'confidence': 0.9374580979347229, 'boundingBox': {'x': 151, 'y': 0, 'w': 84, 'h': 85}}, {'text': 'a close up of a jacket', 'confidence': 0.7757164239883423, 'boundingBox': {'x': 112, 'y': 63, 'w': 149, 'h': 387}}, {'text': "a close-up of a woman's legs", 'confidence': 0.8460952043533325, 'boundingBox': {'x': 149, 'y': 642, 'w': 92, 'h': 155}}, {'text': "a close-up of a woman's legs", 'confidence': 0.8657164573669434, 'boundingBox': {'x': 0, 'y': 670, 'w': 393, 'h': 122}}, {'text': 'a white wall with a brown edge', 'confidence': 0.6364432573318481, 'boundingBox': {'x': 3, 'y': 340, 'w': 107, 'h': 342}}, {'text': "a close-up of a woman's skin", 'confidence': 0.8082153797149658, 'boundingBox': {'x': 122, 'y': 424, 'w': 120, 'h': 235}}]}, 'metadata': {'width': 400, 'height': 800}, 'tagsResult': {'values': [{'name': 'clothing', 'confidence': 0.9995061159133911}, {'name': 'fashion', 'confidence': 0.9719114303588867}, {'name': 'person', 'confidence': 0.9708497524261475}, {'name': 'fashion design', 'confidence': 0.9699382781982422}, {'name': 'fashion model', 'confidence': 0.9362046718597412}, {'name': 'pattern (fashion design)', 'confidence': 0.9285190105438232}, {'name': 'coat', 'confidence': 0.9184257984161377}, {'name': 'outerwear', 'confidence': 0.9108699560165405}, {'name': 'day dress', 'confidence': 0.9097860455513}, {'name': 'dress', 'confidence': 0.8859500885009766}, {'name': 'shoulder', 'confidence': 0.8847154974937439}, {'name': 'blazer', 'confidence': 0.8841245174407959}, {'name': 'fashion accessory', 'confidence': 0.8795701265335083}, {'name': 'casual dress', 'confidence': 0.871787428855896}, {'name': 'button', 'confidence': 0.8602299690246582}, {'name': 'collar', 'confidence': 0.8600295782089233}, {'name': 'sleeve', 'confidence': 0.8486815094947815}, {'name': 'waist', 'confidence': 0.8481172323226929}, {'name': 'sheath dress', 'confidence': 0.846332311630249}, {'name': 'duster', 'confidence': 0.8446614742279053}, {'name': 'blouse', 'confidence': 0.8403252959251404}, {'name': 'wall', 'confidence': 0.8180920481681824}, {'name': 'woman', 'confidence': 0.7238470315933228}, {'name': 'standing', 'confidence': 0.7205101847648621}, {'name': 'indoor', 'confidence': 0.681882381439209}, {'name': 'fabric', 'confidence': 0.6413652300834656}, {'name': 'floor', 'confidence': 0.5951852202415466}, {'name': 'wearing', 'confidence': 0.5914397239685059}]}, 'objectsResult': {'values': []}, 'readResult': {'blocks': []}, 'peopleResult': {'values': [{'boundingBox': {'x': 101, 'y': 1, 'w': 177, 'h': 795}, 'confidence': 0.05512590333819389}]}}
Caption: a woman in a pink suit (Confidence: 0.7796657681465149)
Tags:
- clothing (Confidence: 0.9995061159133911)
- fashion (Confidence: 0.9719114303588867)
- person (Confidence: 0.9708497524261475)
- fashion design (Confidence: 0.9699382781982422)
- fashion model (Confidence: 0.9362046718597412)
- pattern (fashion design) (Confidence: 0.9285190105438232)
- coat (Confidence: 0.9184257984161377)
- outerwear (Confidence: 0.9108699560165405)
- day dress (Confidence: 0.9097860455513)
- dress (Confidence: 0.8859500885009766)
- shoulder (Confidence: 0.8847154974937439)
- blazer (Confidence: 0.8841245174407959)
- fashion accessory (Confidence: 0.8795701265335083)
- casual dress (Confidence: 0.871787428855896)
- button (Confidence: 0.8602299690246582)
- collar (Confidence: 0.8600295782089233)
- sleeve (Confidence: 0.8486815094947815)
- waist (Confidence: 0.8481172323226929)
- sheath dress (Confidence: 0.846332311630249)
- duster (Confidence: 0.8446614742279053)
- blouse (Confidence: 0.8403252959251404)
- wall (Confidence: 0.8180920481681824)
- woman (Confidence: 0.7238470315933228)
- standing (Confidence: 0.7205101847648621)
- indoor (Confidence: 0.681882381439209)
- fabric (Confidence: 0.6413652300834656)
- floor (Confidence: 0.5951852202415466)
- wearing (Confidence: 0.5914397239685059)
Dense Captions:
- a woman in a pink suit (Confidence: 0.7796657681465149)
- a close up of a woman's dress (Confidence: 0.7212175726890564)
- a close up of a bag (Confidence: 0.7956770062446594)
- a close-up of a woman's face (Confidence: 0.9374580979347229)
- a close up of a jacket (Confidence: 0.7757164239883423)
- a close-up of a woman's legs (Confidence: 0.8460952043533325)
- a close-up of a woman's legs (Confidence: 0.8657164573669434)
- a white wall with a brown edge (Confidence: 0.6364432573318481)
- a close-up of a woman's skin (Confidence: 0.8082153797149658)
Analyzing image: D:\Dinesh\Tech\GitHub\virtual-assistant\images\American\resized_images\women\Run1\resized_images\F_9.png
{'modelVersion': '2023-10-01', 'captionResult': {'text': 'a woman in a red suit', 'confidence': 0.8577043414115906}, 'denseCaptionsResult': {'values': [{'text': 'a woman in a red suit', 'confidence': 0.8577043414115906, 'boundingBox': {'x': 0, 'y': 0, 'w': 400, 'h': 800}}, {'text': "a close up of a woman's body", 'confidence': 0.7978391647338867, 'boundingBox': {'x': 110, 'y': 88, 'w': 182, 'h': 628}}, {'text': "a close-up of a woman's feet", 'confidence': 0.8186882734298706, 'boundingBox': {'x': 153, 'y': 687, 'w': 71, 'h': 109}}, {'text': 'a close-up of a woman', 'confidence': 0.920560896396637, 'boundingBox': {'x': 137, 'y': 17, 'w': 111, 'h': 179}}, {'text': 'a woman wearing a red suit', 'confidence': 0.7878881096839905, 'boundingBox': {'x': 108, 'y': 134, 'w': 168, 'h': 283}}, {'text': 'a close up of a window', 'confidence': 0.806471049785614, 'boundingBox': {'x': 267, 'y': 0, 'w': 120, 'h': 665}}, {'text': 'a blurry image of a door handle', 'confidence': 0.7564160227775574, 'boundingBox': {'x': 0, 'y': 0, 'w': 103, 'h': 689}}, {'text': 'a woman wearing red shoes', 'confidence': 0.729995846748352, 'boundingBox': {'x': 0, 'y': 443, 'w': 382, 'h': 348}}, {'text': 'a close up of a red jacket', 'confidence': 0.7566435933113098, 'boundingBox': {'x': 132, 'y': 298, 'w': 126, 'h': 110}}, {'text': "a close up of a woman's skirt", 'confidence': 0.8096569180488586, 'boundingBox': {'x': 128, 'y': 388, 'w': 132, 'h': 184}}]}, 'metadata': {'width': 400, 'height': 800}, 'tagsResult': {'values': [{'name': 'clothing', 'confidence': 0.9966444969177246}, {'name': 'person', 'confidence': 0.9906521439552307}, {'name': 'fashion', 'confidence': 0.98537677526474}, {'name': 'fashion design', 'confidence': 0.9766401052474976}, {'name': 'fashion model', 'confidence': 0.9642693400382996}, {'name': 'high heels', 'confidence': 0.949908971786499}, {'name': 'day dress', 'confidence': 0.940883457660675}, {'name': 'shoulder', 'confidence': 0.9373321533203125}, {'name': 'cocktail dress', 'confidence': 0.919298529624939}, {'name': 'waist', 'confidence': 0.9148350954055786}, {'name': 'woman', 'confidence': 0.8907544016838074}, {'name': 'fashion accessory', 'confidence': 0.8906106948852539}, {'name': 'red', 'confidence': 0.8856499791145325}, {'name': 'casual dress', 'confidence': 0.8827752470970154}, {'name': 'footwear', 'confidence': 0.8826475739479065}, {'name': 'sheath dress', 'confidence': 0.8773446083068848}, {'name': 'pattern (fashion design)', 'confidence': 0.8749680519104004}, {'name': 'sandal', 'confidence': 0.8709770441055298}, {'name': 'model', 'confidence': 0.8698287010192871}, {'name': 'lady', 'confidence': 0.8592513799667358}, {'name': 'fashion show', 'confidence': 0.845306396484375}, {'name': 'indoor', 'confidence': 0.8431221842765808}, {'name': 'fabric', 'confidence': 0.7826216220855713}, {'name': 'wall', 'confidence': 0.7464608550071716}, {'name': 'floor', 'confidence': 0.7345720529556274}, {'name': 'wearing', 'confidence': 0.7234100103378296}, {'name': 'standing', 'confidence': 0.6678606271743774}, {'name': 'dress', 'confidence': 0.6655608415603638}]}, 'objectsResult': {'values': []}, 'readResult': {'blocks': []}, 'peopleResult': {'values': [{'boundingBox': {'x': 110, 'y': 15, 'w': 176, 'h': 784}, 'confidence': 0.9120821356773376}, {'boundingBox': {'x': 116, 'y': 303, 'w': 156, 'h': 193}, 'confidence': 0.0016447416273877025}]}}
Caption: a woman in a red suit (Confidence: 0.8577043414115906)
Tags:
- clothing (Confidence: 0.9966444969177246)
- person (Confidence: 0.9906521439552307)
- fashion (Confidence: 0.98537677526474)
- fashion design (Confidence: 0.9766401052474976)
- fashion model (Confidence: 0.9642693400382996)
- high heels (Confidence: 0.949908971786499)
- day dress (Confidence: 0.940883457660675)
- shoulder (Confidence: 0.9373321533203125)
- cocktail dress (Confidence: 0.919298529624939)
- waist (Confidence: 0.9148350954055786)
- woman (Confidence: 0.8907544016838074)
- fashion accessory (Confidence: 0.8906106948852539)
- red (Confidence: 0.8856499791145325)
- casual dress (Confidence: 0.8827752470970154)
- footwear (Confidence: 0.8826475739479065)
- sheath dress (Confidence: 0.8773446083068848)
- pattern (fashion design) (Confidence: 0.8749680519104004)
- sandal (Confidence: 0.8709770441055298)
- model (Confidence: 0.8698287010192871)
- lady (Confidence: 0.8592513799667358)
- fashion show (Confidence: 0.845306396484375)
- indoor (Confidence: 0.8431221842765808)
- fabric (Confidence: 0.7826216220855713)
- wall (Confidence: 0.7464608550071716)
- floor (Confidence: 0.7345720529556274)
- wearing (Confidence: 0.7234100103378296)
- standing (Confidence: 0.6678606271743774)
- dress (Confidence: 0.6655608415603638)
Dense Captions:
- a woman in a red suit (Confidence: 0.8577043414115906)
- a close up of a woman's body (Confidence: 0.7978391647338867)
- a close-up of a woman's feet (Confidence: 0.8186882734298706)
- a close-up of a woman (Confidence: 0.920560896396637)
- a woman wearing a red suit (Confidence: 0.7878881096839905)
- a close up of a window (Confidence: 0.806471049785614)
- a blurry image of a door handle (Confidence: 0.7564160227775574)
- a woman wearing red shoes (Confidence: 0.729995846748352)
- a close up of a red jacket (Confidence: 0.7566435933113098)
- a close up of a woman's skirt (Confidence: 0.8096569180488586)
